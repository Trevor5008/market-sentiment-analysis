{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source-Level Sentiment Analysis\n",
    "\n",
    "Not all news sources are created equal. Some outlets tend to run more sensational headlines, others stick to dry factual reporting. Some focus heavily on certain tickers, others spread coverage thin.\n",
    "\n",
    "This notebook explores **how sentiment varies by news source** (the `domain` column in our GDELT data). The goal is to understand:\n",
    "\n",
    "1. Which sources contribute the most coverage?\n",
    "2. Do certain sources skew positive or negative?\n",
    "3. How does source sentiment vary by ticker?\n",
    "4. Are there sources we might want to weight differently (or exclude) in downstream analysis?\n",
    "\n",
    "This kind of analysis matters because if we later build signals from sentiment, we don't want a single noisy source dominating the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Project path setup (works from notebook dir or project root)\n",
    "current = Path.cwd()\n",
    "while not (current / \"data\").exists() and current != current.parent:\n",
    "    current = current.parent\n",
    "PROJECT_ROOT = current\n",
    "\n",
    "# We need the sentiment-scored data\n",
    "# If gdelt_articles_with_sentiment.csv doesn't exist yet, fall back to clean + compute scores\n",
    "SENTIMENT_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"gdelt_articles_with_sentiment.csv\"\n",
    "CLEAN_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"gdelt_articles_clean.csv\"\n",
    "\n",
    "if SENTIMENT_PATH.exists():\n",
    "    df = pd.read_csv(SENTIMENT_PATH, parse_dates=[\"seendate\"])\n",
    "    print(f\"Loaded {len(df):,} rows from {SENTIMENT_PATH.name}\")\n",
    "elif CLEAN_PATH.exists():\n",
    "    # Fall back to clean data and add sentiment on the fly\n",
    "    import sys\n",
    "    sys.path.insert(0, str(PROJECT_ROOT / \"scripts\"))\n",
    "    from add_sentiment import add_sentiment_scores\n",
    "    \n",
    "    df = pd.read_csv(CLEAN_PATH, parse_dates=[\"seendate\"])\n",
    "    df = add_sentiment_scores(df, text_col=\"title\")\n",
    "    print(f\"Loaded {len(df):,} rows from {CLEAN_PATH.name} (computed sentiment on the fly)\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No GDELT data found. Run the pipeline first.\")\n",
    "\n",
    "# Quick sanity check\n",
    "required_cols = [\"domain\", \"sentiment_score\", \"ticker\", \"title\"]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns: {missing}\")\n",
    "    \n",
    "print(f\"Unique sources: {df['domain'].nunique()}\")\n",
    "print(f\"Date range: {df['seendate'].min().date()} to {df['seendate'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Who's Writing About Our Tickers?\n",
    "\n",
    "Before we look at sentiment, let's just see which sources show up most often. This tells us where most of our data is coming from—and flags any sources that might be over- or under-represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Article counts by source\n",
    "source_counts = df.groupby(\"domain\").size().sort_values(ascending=False)\n",
    "\n",
    "print(f\"Total articles: {len(df):,}\")\n",
    "print(f\"Total sources: {len(source_counts)}\")\n",
    "print()\n",
    "\n",
    "# Top 15 sources\n",
    "top_n = 15\n",
    "print(f\"Top {top_n} sources by article count:\")\n",
    "print(\"=\" * 50)\n",
    "for i, (domain, count) in enumerate(source_counts.head(top_n).items(), 1):\n",
    "    pct = 100 * count / len(df)\n",
    "    print(f\"{i:2}. {domain:35} {count:5,} ({pct:5.1f}%)\")\n",
    "\n",
    "# How concentrated is coverage?\n",
    "top5_share = source_counts.head(5).sum() / len(df) * 100\n",
    "top10_share = source_counts.head(10).sum() / len(df) * 100\n",
    "print()\n",
    "print(f\"Top 5 sources account for {top5_share:.1f}% of articles\")\n",
    "print(f\"Top 10 sources account for {top10_share:.1f}% of articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: bar chart of top sources\n",
    "top_sources = source_counts.head(12)\n",
    "ax1 = axes[0]\n",
    "bars = ax1.barh(range(len(top_sources)), top_sources.values, color=\"steelblue\")\n",
    "ax1.set_yticks(range(len(top_sources)))\n",
    "ax1.set_yticklabels(top_sources.index)\n",
    "ax1.invert_yaxis()  # largest at top\n",
    "ax1.set_xlabel(\"Article Count\")\n",
    "ax1.set_title(\"Top 12 Sources by Volume\")\n",
    "\n",
    "# Add count labels\n",
    "for bar, count in zip(bars, top_sources.values):\n",
    "    ax1.text(bar.get_width() + 2, bar.get_y() + bar.get_height()/2, \n",
    "             f\"{count:,}\", va=\"center\", fontsize=9)\n",
    "\n",
    "# Right: cumulative distribution (how many sources to get X% of articles)\n",
    "ax2 = axes[1]\n",
    "cumulative = source_counts.cumsum() / source_counts.sum() * 100\n",
    "ax2.plot(range(1, len(cumulative)+1), cumulative.values, marker=\".\", markersize=3)\n",
    "ax2.axhline(80, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"80% threshold\")\n",
    "ax2.axhline(95, color=\"orange\", linestyle=\"--\", alpha=0.7, label=\"95% threshold\")\n",
    "ax2.set_xlabel(\"Number of Sources (ranked by volume)\")\n",
    "ax2.set_ylabel(\"Cumulative % of Articles\")\n",
    "ax2.set_title(\"Coverage Concentration\")\n",
    "ax2.legend()\n",
    "ax2.set_xlim(0, min(50, len(cumulative)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find how many sources needed for 80% and 95%\n",
    "n_80 = (cumulative <= 80).sum() + 1\n",
    "n_95 = (cumulative <= 95).sum() + 1\n",
    "print(f\"Need {n_80} sources to cover 80% of articles\")\n",
    "print(f\"Need {n_95} sources to cover 95% of articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Source-Level Sentiment Profiles\n",
    "\n",
    "Now the interesting part: do different sources have different \"tones\"?\n",
    "\n",
    "We'll compute several metrics for each source:\n",
    "- **avg_sentiment**: mean sentiment score (are they generally positive or negative?)\n",
    "- **sentiment_std**: how much does their sentiment vary?\n",
    "- **positive_rate / negative_rate**: what fraction of their articles are positive vs negative?\n",
    "- **neutral_rate**: what fraction score exactly 0 (no sentiment words matched)?\n",
    "\n",
    "The neutral rate is particularly interesting—a high neutral rate might mean the source uses vocabulary our lexicon doesn't capture, or they write very dry headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build source-level aggregations\n",
    "source_agg = df.groupby(\"domain\").agg(\n",
    "    article_count=(\"url\", \"count\"),\n",
    "    avg_sentiment=(\"sentiment_score\", \"mean\"),\n",
    "    median_sentiment=(\"sentiment_score\", \"median\"),\n",
    "    sentiment_std=(\"sentiment_score\", \"std\"),\n",
    "    positive_rate=(\"sentiment_score\", lambda x: (x > 0).mean()),\n",
    "    negative_rate=(\"sentiment_score\", lambda x: (x < 0).mean()),\n",
    "    neutral_rate=(\"sentiment_score\", lambda x: (x == 0).mean()),\n",
    ").round(3)\n",
    "\n",
    "# Add a \"sentiment_signal_rate\" = 1 - neutral_rate (how often does the lexicon fire)\n",
    "source_agg[\"signal_rate\"] = (1 - source_agg[\"neutral_rate\"]).round(3)\n",
    "\n",
    "# Sort by article count for now\n",
    "source_agg = source_agg.sort_values(\"article_count\", ascending=False)\n",
    "\n",
    "print(\"Source sentiment profiles (top 20 by volume):\")\n",
    "print(\"=\" * 100)\n",
    "display_cols = [\"article_count\", \"avg_sentiment\", \"sentiment_std\", \"positive_rate\", \"negative_rate\", \"signal_rate\"]\n",
    "print(source_agg[display_cols].head(20).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which sources skew most positive or negative?\n",
    "\n",
    "Let's filter to sources with at least 10 articles (so the averages mean something) and see who's on the extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to sources with meaningful sample size\n",
    "min_articles = 10\n",
    "source_agg_filtered = source_agg[source_agg[\"article_count\"] >= min_articles].copy()\n",
    "print(f\"Sources with >= {min_articles} articles: {len(source_agg_filtered)}\")\n",
    "print()\n",
    "\n",
    "# Most positive sources\n",
    "print(\"Most POSITIVE sources (by avg sentiment):\")\n",
    "print(\"-\" * 60)\n",
    "most_positive = source_agg_filtered.nlargest(8, \"avg_sentiment\")\n",
    "for domain, row in most_positive.iterrows():\n",
    "    print(f\"  {domain:35} avg={row['avg_sentiment']:+.3f}  (n={int(row['article_count'])})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Most negative sources\n",
    "print(\"Most NEGATIVE sources (by avg sentiment):\")\n",
    "print(\"-\" * 60)\n",
    "most_negative = source_agg_filtered.nsmallest(8, \"avg_sentiment\")\n",
    "for domain, row in most_negative.iterrows():\n",
    "    print(f\"  {domain:35} avg={row['avg_sentiment']:+.3f}  (n={int(row['article_count'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: avg sentiment vs signal rate (how often lexicon fires)\n",
    "# This shows us: are positive sources just using more sentiment words, or are they actually biased?\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Size by article count (log scale for visibility)\n",
    "sizes = np.log1p(source_agg_filtered[\"article_count\"]) * 15\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    source_agg_filtered[\"signal_rate\"],\n",
    "    source_agg_filtered[\"avg_sentiment\"],\n",
    "    s=sizes,\n",
    "    alpha=0.6,\n",
    "    c=source_agg_filtered[\"avg_sentiment\"],\n",
    "    cmap=\"RdYlGn\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "# Reference lines\n",
    "ax.axhline(0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax.axvline(source_agg_filtered[\"signal_rate\"].median(), color=\"gray\", linestyle=\":\", alpha=0.5)\n",
    "\n",
    "# Label some interesting outliers\n",
    "# Top 5 by absolute avg_sentiment\n",
    "to_label = source_agg_filtered.nlargest(4, \"avg_sentiment\").index.tolist()\n",
    "to_label += source_agg_filtered.nsmallest(3, \"avg_sentiment\").index.tolist()\n",
    "to_label += source_agg_filtered.nlargest(3, \"article_count\").index.tolist()\n",
    "to_label = list(set(to_label))  # dedupe\n",
    "\n",
    "for domain in to_label:\n",
    "    row = source_agg_filtered.loc[domain]\n",
    "    ax.annotate(\n",
    "        domain.replace(\".com\", \"\").replace(\".org\", \"\"),\n",
    "        (row[\"signal_rate\"], row[\"avg_sentiment\"]),\n",
    "        fontsize=8,\n",
    "        alpha=0.8,\n",
    "        xytext=(5, 5),\n",
    "        textcoords=\"offset points\"\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Signal Rate (fraction of articles with sentiment words)\")\n",
    "ax.set_ylabel(\"Average Sentiment Score\")\n",
    "ax.set_title(\"Source Sentiment Profile\\n(bubble size = article count, color = sentiment)\")\n",
    "plt.colorbar(scatter, label=\"Avg Sentiment\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Source Coverage by Ticker\n",
    "\n",
    "Do different sources focus on different stocks? This matters because if, say, source A only covers TSLA and source B only covers NVDA, then comparing their sentiment isn't apples-to-apples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tab: source × ticker article counts\n",
    "source_ticker_counts = pd.crosstab(df[\"domain\"], df[\"ticker\"])\n",
    "\n",
    "# Focus on top sources\n",
    "top_sources_list = source_counts.head(12).index.tolist()\n",
    "source_ticker_top = source_ticker_counts.loc[top_sources_list]\n",
    "\n",
    "# Normalize by row (what % of each source's articles go to each ticker)\n",
    "source_ticker_pct = source_ticker_top.div(source_ticker_top.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(\"Ticker coverage by source (% of source's articles):\")\n",
    "print(source_ticker_pct.round(1).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of ticker coverage\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(\n",
    "    source_ticker_pct,\n",
    "    annot=True,\n",
    "    fmt=\".0f\",\n",
    "    cmap=\"YlOrRd\",\n",
    "    ax=ax,\n",
    "    cbar_kws={\"label\": \"% of source articles\"}\n",
    ")\n",
    "ax.set_title(\"How Sources Distribute Coverage Across Tickers\")\n",
    "ax.set_xlabel(\"Ticker\")\n",
    "ax.set_ylabel(\"Source\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Source × Ticker Sentiment\n",
    "\n",
    "Now the real question: for the same ticker, do different sources give different sentiment signals?\n",
    "\n",
    "If source A is always more positive about NVDA than source B, that could be useful info. Or it could just be noise we need to normalize out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source × ticker sentiment\n",
    "source_ticker_sentiment = df.groupby([\"domain\", \"ticker\"]).agg(\n",
    "    count=(\"url\", \"count\"),\n",
    "    avg_sentiment=(\"sentiment_score\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "# Filter to meaningful sample sizes\n",
    "source_ticker_sentiment = source_ticker_sentiment[source_ticker_sentiment[\"count\"] >= 5]\n",
    "\n",
    "# Pivot for heatmap\n",
    "sentiment_pivot = source_ticker_sentiment.pivot(\n",
    "    index=\"domain\",\n",
    "    columns=\"ticker\",\n",
    "    values=\"avg_sentiment\"\n",
    ")\n",
    "\n",
    "# Filter to top sources\n",
    "sentiment_pivot_top = sentiment_pivot.loc[\n",
    "    sentiment_pivot.index.isin(source_counts.head(15).index)\n",
    "].dropna(how=\"all\")\n",
    "\n",
    "print(f\"Source × Ticker sentiment (top sources, min 5 articles per cell):\")\n",
    "print(sentiment_pivot_top.round(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of source × ticker sentiment\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Use diverging colormap centered at 0\n",
    "vmax = max(abs(sentiment_pivot_top.min().min()), abs(sentiment_pivot_top.max().max()))\n",
    "vmax = min(vmax, 0.5)  # cap for better contrast\n",
    "\n",
    "sns.heatmap(\n",
    "    sentiment_pivot_top,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"RdYlGn\",\n",
    "    center=0,\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    "    ax=ax,\n",
    "    cbar_kws={\"label\": \"Avg Sentiment\"}\n",
    ")\n",
    "ax.set_title(\"Average Sentiment by Source and Ticker\\n(green = positive, red = negative)\")\n",
    "ax.set_xlabel(\"Ticker\")\n",
    "ax.set_ylabel(\"Source\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Sentiment Consistency Within Sources\n",
    "\n",
    "Are some sources more \"consistent\" in their sentiment (always positive or always negative), while others swing wildly?\n",
    "\n",
    "High standard deviation might mean:\n",
    "- The source covers a wide range of news (good and bad)\n",
    "- Or it's just noisy\n",
    "\n",
    "Low standard deviation might mean:\n",
    "- The source has a consistent editorial slant\n",
    "- Or it writes boring headlines that don't trigger our lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at sentiment distribution for a few key sources\n",
    "key_sources = source_counts.head(6).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, source in enumerate(key_sources):\n",
    "    ax = axes[i]\n",
    "    source_data = df[df[\"domain\"] == source][\"sentiment_score\"]\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    ax.hist(source_data, bins=30, density=True, alpha=0.7, color=\"steelblue\", edgecolor=\"white\")\n",
    "    \n",
    "    # Stats\n",
    "    mean_sent = source_data.mean()\n",
    "    std_sent = source_data.std()\n",
    "    n = len(source_data)\n",
    "    neutral_pct = (source_data == 0).mean() * 100\n",
    "    \n",
    "    ax.axvline(mean_sent, color=\"red\", linestyle=\"--\", label=f\"mean={mean_sent:.2f}\")\n",
    "    ax.axvline(0, color=\"gray\", linestyle=\":\", alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f\"{source}\\n(n={n}, neutral={neutral_pct:.0f}%)\")\n",
    "    ax.set_xlabel(\"Sentiment Score\")\n",
    "    ax.set_xlim(-1.1, 1.1)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle(\"Sentiment Distribution by Source\", fontsize=12, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Takeaways and Recommendations\n",
    "\n",
    "Let's summarize what we learned and think about implications for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats\n",
    "print(\"=\" * 70)\n",
    "print(\"SOURCE-LEVEL SENTIMENT SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Coverage concentration\n",
    "print(\"COVERAGE:\")\n",
    "print(f\"  • {len(source_counts)} unique sources\")\n",
    "print(f\"  • Top 5 sources = {top5_share:.1f}% of articles\")\n",
    "print(f\"  • Top 10 sources = {top10_share:.1f}% of articles\")\n",
    "print()\n",
    "\n",
    "# Sentiment variation across sources\n",
    "avg_range = source_agg_filtered[\"avg_sentiment\"].max() - source_agg_filtered[\"avg_sentiment\"].min()\n",
    "print(\"SENTIMENT VARIATION:\")\n",
    "print(f\"  • Average sentiment ranges from {source_agg_filtered['avg_sentiment'].min():.3f} to {source_agg_filtered['avg_sentiment'].max():.3f}\")\n",
    "print(f\"  • Spread across sources: {avg_range:.3f}\")\n",
    "print(f\"  • Overall mean sentiment: {df['sentiment_score'].mean():.3f}\")\n",
    "print()\n",
    "\n",
    "# Signal rates\n",
    "print(\"LEXICON MATCH RATES:\")\n",
    "print(f\"  • Overall: {100*(df['sentiment_score'] != 0).mean():.1f}% of articles have sentiment words\")\n",
    "print(f\"  • By source: ranges from {source_agg_filtered['signal_rate'].min()*100:.1f}% to {source_agg_filtered['signal_rate'].max()*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# Potential outliers/concerns\n",
    "print(\"NOTABLE SOURCES:\")\n",
    "if len(most_positive) > 0:\n",
    "    top_pos = most_positive.iloc[0]\n",
    "    print(f\"  • Most positive: {most_positive.index[0]} (avg={top_pos['avg_sentiment']:.3f}, n={int(top_pos['article_count'])})\")\n",
    "if len(most_negative) > 0:\n",
    "    top_neg = most_negative.iloc[0]\n",
    "    print(f\"  • Most negative: {most_negative.index[0]} (avg={top_neg['avg_sentiment']:.3f}, n={int(top_neg['article_count'])})\")\n",
    "    \n",
    "# Highest volume\n",
    "top_vol = source_agg.iloc[0]\n",
    "print(f\"  • Highest volume: {source_agg.index[0]} ({int(top_vol['article_count'])} articles, avg={top_vol['avg_sentiment']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What This Means for Analysis\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "1. **Coverage is concentrated** — a handful of sources dominate the data. This means if those sources have a bias, it'll show up in aggregate sentiment.\n",
    "\n",
    "2. **Sources do differ in average sentiment** — some are consistently more positive, others more negative. This could reflect editorial slant, or just the type of news they cover.\n",
    "\n",
    "3. **Lexicon match rates vary** — some sources use more \"sentiment-rich\" language, others are drier. High neutral rates don't mean the source is actually neutral; it might just mean our lexicon doesn't capture their vocabulary.\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- **For aggregate sentiment signals**: Consider weighting by source to avoid letting high-volume sources dominate. Or use median instead of mean.\n",
    "\n",
    "- **For ticker-specific analysis**: Be aware that if source A covers NVDA heavily and source B covers TSLA, comparing their sentiment isn't straightforward.\n",
    "\n",
    "- **For robustness checks**: Try running analysis with and without the most extreme sources to see if conclusions hold.\n",
    "\n",
    "- **For future work**: Could explore whether certain sources are more \"predictive\" of price moves — maybe some outlets' sentiment actually matters more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the source aggregation table for reference\n",
    "output_path = PROJECT_ROOT / \"data\" / \"processed\" / \"source_sentiment_summary.csv\"\n",
    "source_agg.to_csv(output_path)\n",
    "print(f\"Saved source summary to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
