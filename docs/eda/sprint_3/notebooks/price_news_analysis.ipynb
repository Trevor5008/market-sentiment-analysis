{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Price–News Join Analysis\n",
        "\n",
        "Analyze the GDELT–OHLCV join table: **news on day t → prices on day t+1** (next trading day).  \n",
        "We evaluate and validate the data, then compute mean and median sentiment (and optional price metrics) per ticker per day.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Find project root\n",
        "current = Path.cwd()\n",
        "while not (current / \"data\").exists() and current != current.parent:\n",
        "    current = current.parent\n",
        "PROJECT_ROOT = current\n",
        "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
        "INPUT_PATH = PROCESSED_DIR / \"gdelt_ohlcv_join.csv\"\n",
        "\n",
        "df = pd.read_csv(\n",
        "    INPUT_PATH,\n",
        "    parse_dates=[\"seendate\", \"article_date\", \"price_date\"],\n",
        ")\n",
        "# Required for analysis\n",
        "required = [\"sentiment_score\", \"ticker\", \"article_date\", \"price_date\"]\n",
        "missing = [c for c in required if c not in df.columns]\n",
        "assert not missing, f\"Missing columns: {missing}\"\n",
        "print(f\"Loaded {len(df):,} rows from {INPUT_PATH.name}\")\n",
        "print(f\"Columns: {list(df.columns)}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 3,090 rows from gdelt_ohlcv_join.csv\n",
            "Columns: ['seendate', 'url', 'title', 'language', 'domain', 'socialimage', 'company', 'ticker', 'sentiment_score', 'sentiment_hits', 'sentiment_present', 'article_date', 'price_date', 'next_open', 'next_high', 'next_low', 'next_close', 'next_adj_close', 'next_volume']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data evaluation and validation\n",
        "\n",
        "**First objective: validate the matching between prices and news** (join integrity, then schema and coverage)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Schema and shape\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nDtypes:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nKey columns present:\")\n",
        "key_cols = [\"article_date\", \"price_date\", \"ticker\", \"sentiment_score\", \"next_close\", \"next_volume\"]\n",
        "for c in key_cols:\n",
        "    print(f\"  {c}: {c in df.columns}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (3090, 19)\n",
            "\n",
            "Dtypes:\n",
            "seendate             datetime64[us, UTC]\n",
            "url                                  str\n",
            "title                                str\n",
            "language                             str\n",
            "domain                               str\n",
            "socialimage                          str\n",
            "company                              str\n",
            "ticker                               str\n",
            "sentiment_score                  float64\n",
            "sentiment_hits                   float64\n",
            "sentiment_present                   bool\n",
            "article_date              datetime64[us]\n",
            "price_date                datetime64[us]\n",
            "next_open                        float64\n",
            "next_high                        float64\n",
            "next_low                         float64\n",
            "next_close                       float64\n",
            "next_adj_close                   float64\n",
            "next_volume                        int64\n",
            "dtype: object\n",
            "\n",
            "Key columns present:\n",
            "  article_date: True\n",
            "  price_date: True\n",
            "  ticker: True\n",
            "  sentiment_score: True\n",
            "  next_close: True\n",
            "  next_volume: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Validate price–news matching\n",
        "\n",
        "Check that **price_date** is the next trading day after **article_date** and that attached prices match the source OHLCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 1) price_date must be strictly after article_date (next trading day)\n",
        "df[\"_gap_days\"] = (df[\"price_date\"] - df[\"article_date\"]).dt.days\n",
        "bad_order = (df[\"_gap_days\"] <= 0).sum()\n",
        "print(\"1) Article date → price date (next trading day)\")\n",
        "# Display number of misaligned rows (s/b 0)\n",
        "print(f\"   Rows where price_date ≤ article_date: {bad_order} (expect 0)\")\n",
        "# Unit test for correct matching\n",
        "assert bad_order == 0, \"Every row must have price_date > article_date\"\n",
        "print(\"   ✓ All rows have price_date after article_date\")\n",
        "print(\"\\n   Calendar-day gap (article_date to price_date):\")\n",
        "print(df[\"_gap_days\"].value_counts().sort_index().to_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1) Article date → price date (next trading day)\n",
            "   Rows where price_date ≤ article_date: 0 (expect 0)\n",
            "   ✓ All rows have price_date after article_date\n",
            "\n",
            "   Calendar-day gap (article_date to price_date):\n",
            "_gap_days\n",
            "1    2873\n",
            "2      86\n",
            "3     131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2) Within join: each (price_date, ticker) should have exactly one set of next_* values (no conflicts)\n",
        "price_cols = [c for c in df.columns if c.startswith(\"next_\")]\n",
        "check = df.groupby([\"price_date\", \"ticker\"])[price_cols].nunique()\n",
        "max_per_col = check.max()\n",
        "conflicts = (check > 1).any(axis=1).sum()\n",
        "print(\"2) One price per (price_date, ticker)\")\n",
        "print(f\"   Unique (price_date, ticker) pairs: {len(check):,}\")\n",
        "print(f\"   Pairs with conflicting next_* values: {conflicts} (expect 0)\")\n",
        "# Unit test for unique prices per (price_date, ticker)\n",
        "assert conflicts == 0, \"⚠ Some (price_date, ticker) have multiple different prices — investigate\"\n",
        "print(\"   ✓ All rows for same (price_date, ticker) have identical next_* values\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2) One price per (price_date, ticker)\n",
            "   Unique (price_date, ticker) pairs: 97\n",
            "   Pairs with conflicting next_* values: 0 (expect 0)\n",
            "   ✓ All rows for same (price_date, ticker) have identical next_* values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3) Cross-check: join next_* values vs source OHLCV (prices_daily_accumulated)\n",
        "ohlcv_path = PROCESSED_DIR / \"prices_daily_accumulated.csv\"\n",
        "if ohlcv_path.exists():\n",
        "    ohlcv = pd.read_csv(ohlcv_path, parse_dates=[\"date\"])\n",
        "    # One row per (date, ticker) in join; take first next_* per (price_date, ticker)\n",
        "    join_prices = df.groupby([\"price_date\", \"ticker\"])[\"next_close\"].first().reset_index()\n",
        "    join_prices = join_prices.rename(columns={\"price_date\": \"date\", \"next_close\": \"join_close\"})\n",
        "    merged = join_prices.merge(ohlcv[[\"date\", \"ticker\", \"close\"]], on=[\"date\", \"ticker\"], how=\"left\")\n",
        "    merged[\"match\"] = merged[\"join_close\"].round(6) == merged[\"close\"].round(6)\n",
        "    mismatches = (~merged[\"match\"]).sum()\n",
        "    missing = merged[\"close\"].isna().sum()\n",
        "    print(\"3) Join vs source OHLCV (next_close vs close)\")\n",
        "    print(f\"   (price_date, ticker) pairs checked: {len(merged):,}\")\n",
        "    print(f\"   Mismatches (join next_close ≠ OHLCV close): {mismatches}\")\n",
        "    print(f\"   Missing in OHLCV: {missing}\")\n",
        "    # Unit test for matching prices\n",
        "    assert mismatches == 0 and missing == 0, \"   ⚠ Review mismatches or missing dates\"\n",
        "    print(\"   ✓ All join prices match source OHLCV\")\n",
        "else:\n",
        "    print(\"3) Skip cross-check (prices_daily_accumulated.csv not found)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3) Join vs source OHLCV (next_close vs close)\n",
            "   (price_date, ticker) pairs checked: 97\n",
            "   Mismatches (join next_close ≠ OHLCV close): 0\n",
            "   Missing in OHLCV: 0\n",
            "   ✓ All join prices match source OHLCV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Schema, date ranges, and coverage\n",
        "\n",
        "Schema, date ranges, missing values, and ticker coverage (for downstream aggregation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Date ranges and join alignment\n",
        "art_min, art_max = df[\"article_date\"].min(), df[\"article_date\"].max()\n",
        "price_min, price_max = df[\"price_date\"].min(), df[\"price_date\"].max()\n",
        "print(\"Article date range:\", art_min.date(), \"to\", art_max.date())\n",
        "print(\"Price date range: \", price_min.date(), \"to\", price_max.date())\n",
        "print(\"\\nExpected: price_date = next trading day after article_date (weekends/holidays skipped).\")\n",
        "# Spot-check: article_date and price_date should differ by 1–3 calendar days (Fri→Mon = 3)\n",
        "df[\"days_to_next\"] = (df[\"price_date\"] - df[\"article_date\"]).dt.days\n",
        "print(\"\\nCalendar days from article_date to price_date (sample):\")\n",
        "print(df[\"days_to_next\"].value_counts().head(10))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article date range: 2026-01-05 to 2026-02-09\n",
            "Price date range:  2026-01-06 to 2026-02-10\n",
            "\n",
            "Expected: price_date = next trading day after article_date (weekends/holidays skipped).\n",
            "\n",
            "Calendar days from article_date to price_date (sample):\n",
            "days_to_next\n",
            "1    2873\n",
            "3     131\n",
            "2      86\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Missing values in columns used for aggregation\n",
        "agg_cols = [\"sentiment_score\", \"ticker\", \"article_date\", \"price_date\"]\n",
        "if \"next_close\" in df.columns:\n",
        "    agg_cols.append(\"next_close\")\n",
        "missing = df[agg_cols].isna().sum()\n",
        "print(\"Missing values (columns used for mean/median per ticker per day):\")\n",
        "print(missing[missing > 0] if missing.any() else \"  None\")\n",
        "print(\"\\nRows with any missing in these columns:\", df[agg_cols].isna().any(axis=1).sum())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Missing values (columns used for mean/median per ticker per day):\n",
            "  None\n",
            "\n",
            "Rows with any missing in these columns: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ticker coverage: articles and (article_date, ticker) pairs\n",
        "print(\"Articles per ticker:\")\n",
        "print(df[\"ticker\"].value_counts().sort_index())\n",
        "print(\"\\nUnique (article_date, ticker) pairs per ticker = distinct calendar days with ≥1 article:\")\n",
        "# Per ticker, count distinct article_date (same as count of (article_date, ticker) per ticker)\n",
        "unique_days_per_ticker = df.groupby(\"ticker\")[\"article_date\"].nunique()\n",
        "print(unique_days_per_ticker.to_string())\n",
        "print(\"\\n(Multiple articles per day per ticker is expected; we aggregate to mean/median per (date, ticker) later.)\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Articles per ticker:\n",
            "ticker\n",
            "AAPL     306\n",
            "AMZN     320\n",
            "GOOGL    580\n",
            "META     628\n",
            "MSFT     351\n",
            "NVDA     658\n",
            "TSLA     247\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique (article_date, ticker) pairs per ticker = distinct calendar days with ≥1 article:\n",
            "ticker\n",
            "AAPL     12\n",
            "AMZN     14\n",
            "GOOGL    17\n",
            "META     18\n",
            "MSFT     13\n",
            "NVDA     13\n",
            "TSLA     16\n",
            "\n",
            "(Multiple articles per day per ticker is expected; we aggregate to mean/median per (date, ticker) later.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute mean/median sentiment per ticker per day\n",
        "sentiment_per_ticker_per_day = df.groupby([\"ticker\", \"price_date\"])[\"sentiment_score\"].agg([\"mean\", \"median\"])\n",
        "print(\"\\nMean and median sentiment per ticker per day:\")\n",
        "print(sentiment_per_ticker_per_day.head())\n",
        "\n",
        "# Sanity check aggregated outputs across tickers\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean and median sentiment per ticker per day:\n",
            "                       mean  median\n",
            "ticker price_date                  \n",
            "AAPL   2026-01-06  0.417500    0.38\n",
            "       2026-01-07  0.262857    0.00\n",
            "       2026-01-08  0.052500    0.00\n",
            "       2026-01-12  0.317308    0.00\n",
            "       2026-01-13  0.233953    0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sentiment summary statistics per ticker per day\n",
        "\n",
        "Aggregate to mean and median sentiment per (ticker, day)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Aggregate: one row per (article_date, ticker)\n",
        "daily = df.groupby([\"article_date\", \"ticker\"]).agg(\n",
        "    sentiment_mean=(\"sentiment_score\", \"mean\"),\n",
        "    sentiment_median=(\"sentiment_score\", \"median\"),\n",
        "    article_count=(\"sentiment_score\", \"count\"),\n",
        ").reset_index()\n",
        "if \"next_close\" in df.columns:\n",
        "    daily[\"next_close\"] = df.groupby([\"article_date\", \"ticker\"])[\"next_close\"].first().values\n",
        "if \"next_volume\" in df.columns:\n",
        "    daily[\"next_volume\"] = df.groupby([\"article_date\", \"ticker\"])[\"next_volume\"].first().values\n",
        "\n",
        "print(\"Daily summary (first rows):\")\n",
        "daily.head(10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Daily summary (first rows):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_date</th>\n",
              "      <th>ticker</th>\n",
              "      <th>sentiment_mean</th>\n",
              "      <th>sentiment_median</th>\n",
              "      <th>article_count</th>\n",
              "      <th>next_close</th>\n",
              "      <th>next_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.417500</td>\n",
              "      <td>0.38</td>\n",
              "      <td>8</td>\n",
              "      <td>262.359985</td>\n",
              "      <td>52352100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.38</td>\n",
              "      <td>2</td>\n",
              "      <td>240.929993</td>\n",
              "      <td>53764700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.91</td>\n",
              "      <td>2</td>\n",
              "      <td>314.339996</td>\n",
              "      <td>31212100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>0.006667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6</td>\n",
              "      <td>478.510010</td>\n",
              "      <td>23037700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>NVDA</td>\n",
              "      <td>0.411429</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7</td>\n",
              "      <td>187.240005</td>\n",
              "      <td>176862600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>432.959991</td>\n",
              "      <td>89093800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2026-01-06</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.262857</td>\n",
              "      <td>0.00</td>\n",
              "      <td>21</td>\n",
              "      <td>260.329987</td>\n",
              "      <td>48309800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2026-01-06</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>0.206923</td>\n",
              "      <td>0.00</td>\n",
              "      <td>52</td>\n",
              "      <td>241.559998</td>\n",
              "      <td>42236500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2026-01-06</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>0.490769</td>\n",
              "      <td>0.76</td>\n",
              "      <td>13</td>\n",
              "      <td>321.980011</td>\n",
              "      <td>35104400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2026-01-06</td>\n",
              "      <td>META</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>16</td>\n",
              "      <td>648.690002</td>\n",
              "      <td>12846300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  article_date ticker  sentiment_mean  sentiment_median  article_count  \\\n",
              "0   2026-01-05   AAPL        0.417500              0.38              8   \n",
              "1   2026-01-05   AMZN        0.380000              0.38              2   \n",
              "2   2026-01-05  GOOGL        0.910000              0.91              2   \n",
              "3   2026-01-05   MSFT        0.006667              0.00              6   \n",
              "4   2026-01-05   NVDA        0.411429              0.00              7   \n",
              "5   2026-01-05   TSLA        0.066667              0.00              3   \n",
              "6   2026-01-06   AAPL        0.262857              0.00             21   \n",
              "7   2026-01-06   AMZN        0.206923              0.00             52   \n",
              "8   2026-01-06  GOOGL        0.490769              0.76             13   \n",
              "9   2026-01-06   META        0.125000              0.00             16   \n",
              "\n",
              "   next_close  next_volume  \n",
              "0  262.359985     52352100  \n",
              "1  240.929993     53764700  \n",
              "2  314.339996     31212100  \n",
              "3  478.510010     23037700  \n",
              "4  187.240005    176862600  \n",
              "5  432.959991     89093800  \n",
              "6  260.329987     48309800  \n",
              "7  241.559998     42236500  \n",
              "8  321.980011     35104400  \n",
              "9  648.690002     12846300  "
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Monday-only analysis: sentiment per ticker per week\n",
        "\n",
        "Filter to **Mondays only** (article_date), then group by week (7-day increments starting from **2026-01-12** as week 1). Compute summary statistics per ticker per week (open-ended; weeks 1+)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Filter to Mondays only (dayofweek: Monday=0)\n",
        "mondays = daily[daily[\"article_date\"].dt.dayofweek == 0].copy()\n",
        "print(f\"Total rows: {len(daily):,}\")\n",
        "print(f\"Mondays only: {len(mondays):,} ({100*len(mondays)/len(daily):.1f}%)\")\n",
        "print(f\"\\nMonday dates in data:\")\n",
        "monday_dates = sorted(mondays[\"article_date\"].dt.date.unique())\n",
        "print(monday_dates)\n",
        "print(f\"\\nExpected Mondays (if all weeks present):\")\n",
        "week_start = pd.Timestamp(\"2026-01-12\")\n",
        "for w in range(1, 6):  # weeks 1-5 based on data up to 2/9\n",
        "    expected_monday = week_start + pd.Timedelta(days=7*(w-1))\n",
        "    print(f\"  Week {w}: {expected_monday.date()}\")\n",
        "    if expected_monday.date() not in monday_dates:\n",
        "        print(f\"    ⚠ MISSING from data\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total rows: 103\n",
            "Mondays only: 27 (26.2%)\n",
            "\n",
            "Monday dates in data:\n",
            "[datetime.date(2026, 1, 5), datetime.date(2026, 1, 12), datetime.date(2026, 2, 2), datetime.date(2026, 2, 9)]\n",
            "\n",
            "Expected Mondays (if all weeks present):\n",
            "  Week 1: 2026-01-12\n",
            "  Week 2: 2026-01-19\n",
            "    ⚠ MISSING from data\n",
            "  Week 3: 2026-01-26\n",
            "    ⚠ MISSING from data\n",
            "  Week 4: 2026-02-02\n",
            "  Week 5: 2026-02-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Assign week number (increments of 7 days starting from 2026-01-12)\n",
        "# Week 1 = 2026-01-12 + 0-6 days, Week 2 = 2026-01-12 + 7-13 days, etc.\n",
        "week_start_date = pd.Timestamp(\"2026-01-12\")\n",
        "mondays[\"days_since_week1_start\"] = (mondays[\"article_date\"] - week_start_date).dt.days\n",
        "mondays[\"week\"] = (mondays[\"days_since_week1_start\"] // 7) + 1\n",
        "# Explain missing weeks (MLK holiday on 1/19)\n",
        "print(\"Note: MLK holiday on 1/19 causes week 2 to be missing\")\n",
        "# Filter to weeks >= 1 (exclude dates before 1/12, but no upper limit - open-ended)\n",
        "mondays_filtered = mondays[mondays[\"week\"] >= 1].copy()\n",
        "print(f\"Week start date: {week_start_date.date()}\")\n",
        "print(f\"Week range in data: {mondays_filtered['week'].min()} to {mondays_filtered['week'].max()} (open-ended)\")\n",
        "print(f\"\\nMondays per week:\")\n",
        "week_counts = mondays_filtered.groupby(\"week\")[\"article_date\"].nunique()\n",
        "print(week_counts)\n",
        "print(f\"\\nMissing weeks (expected but not present):\")\n",
        "all_weeks = set(range(mondays_filtered['week'].min(), mondays_filtered['week'].max() + 1))\n",
        "present_weeks = set(week_counts.index)\n",
        "missing_weeks = sorted(all_weeks - present_weeks)\n",
        "if missing_weeks:\n",
        "    for w in missing_weeks:\n",
        "        expected_date = week_start_date + pd.Timedelta(days=7*(w-1))\n",
        "        print(f\"  Week {w}: {expected_date.date()} (no articles on this Monday)\")\n",
        "        # Check if this date exists in the raw daily data (not just Mondays)\n",
        "        if expected_date.date() in daily[\"article_date\"].dt.date.values:\n",
        "            print(f\"    → Date exists in daily data but is not a Monday (dayofweek check)\")\n",
        "        else:\n",
        "            print(f\"    → Date not in daily data at all (no articles on this date)\")\n",
        "else:\n",
        "    print(\"  None\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: MLK holiday on 1/19 causes week 2 to be missing\n",
            "Week start date: 2026-01-12\n",
            "Week range in data: 1 to 5 (open-ended)\n",
            "\n",
            "Mondays per week:\n",
            "week\n",
            "1    1\n",
            "4    1\n",
            "5    1\n",
            "Name: article_date, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Summary statistics per ticker per week (Mondays only)\n",
        "# Use mondays_filtered to exclude week 0 (dates before 1/12)\n",
        "weekly_stats = mondays_filtered.groupby([\"ticker\", \"week\"]).agg(\n",
        "    sentiment_mean=(\"sentiment_mean\", \"mean\"),\n",
        "    sentiment_median=(\"sentiment_median\", \"median\"),\n",
        "    # sentiment_std excluded: std of already-aggregated daily means is problematic (NaN when only one Monday)\n",
        "    monday_count=(\"article_date\", \"nunique\"),  # number of Mondays in this week with data\n",
        "    total_articles=(\"article_count\", \"sum\"),\n",
        ").reset_index()\n",
        "\n",
        "print(\"Summary statistics per ticker per week (Mondays only, weeks 1+):\")\n",
        "print(\"=\" * 80)\n",
        "weekly_stats"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary statistics per ticker per week (Mondays only, weeks 1+):\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>week</th>\n",
              "      <th>sentiment_mean</th>\n",
              "      <th>sentiment_median</th>\n",
              "      <th>sentiment_std</th>\n",
              "      <th>monday_count</th>\n",
              "      <th>total_articles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.233953</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>5</td>\n",
              "      <td>0.190857</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.140370</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.190000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>5</td>\n",
              "      <td>0.171714</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GOOGL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GOOGL</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.016667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GOOGL</td>\n",
              "      <td>5</td>\n",
              "      <td>0.172133</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>META</td>\n",
              "      <td>1</td>\n",
              "      <td>0.016897</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>META</td>\n",
              "      <td>4</td>\n",
              "      <td>0.081000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>META</td>\n",
              "      <td>5</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>1</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>5</td>\n",
              "      <td>0.136000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>1</td>\n",
              "      <td>0.364038</td>\n",
              "      <td>0.12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>5</td>\n",
              "      <td>0.211875</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>1</td>\n",
              "      <td>0.087222</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.910000</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>5</td>\n",
              "      <td>0.556000</td>\n",
              "      <td>0.86</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ticker  week  sentiment_mean  sentiment_median  sentiment_std  \\\n",
              "0    AAPL     1        0.233953              0.00            NaN   \n",
              "1    AAPL     4        0.000000              0.00            NaN   \n",
              "2    AAPL     5        0.190857              0.00            NaN   \n",
              "3    AMZN     1        0.140370              0.00            NaN   \n",
              "4    AMZN     4       -0.190000              0.00            NaN   \n",
              "5    AMZN     5        0.171714              0.00            NaN   \n",
              "6   GOOGL     1        0.090000              0.00            NaN   \n",
              "7   GOOGL     4       -0.016667              0.00            NaN   \n",
              "8   GOOGL     5        0.172133              0.00            NaN   \n",
              "9    META     1        0.016897              0.00            NaN   \n",
              "10   META     4        0.081000              0.00            NaN   \n",
              "11   META     5        0.004167              0.00            NaN   \n",
              "12   MSFT     1        0.120000              0.00            NaN   \n",
              "13   MSFT     4        0.000000              0.00            NaN   \n",
              "14   MSFT     5        0.136000              0.00            NaN   \n",
              "15   NVDA     1        0.364038              0.12            NaN   \n",
              "16   NVDA     4        0.000000              0.00            NaN   \n",
              "17   NVDA     5        0.211875              0.00            NaN   \n",
              "18   TSLA     1        0.087222              0.00            NaN   \n",
              "19   TSLA     4       -0.910000             -0.91            NaN   \n",
              "20   TSLA     5        0.556000              0.86            NaN   \n",
              "\n",
              "    monday_count  total_articles  \n",
              "0              1              43  \n",
              "1              1               1  \n",
              "2              1              35  \n",
              "3              1              27  \n",
              "4              1               4  \n",
              "5              1              35  \n",
              "6              1              20  \n",
              "7              1               3  \n",
              "8              1              75  \n",
              "9              1              29  \n",
              "10             1              30  \n",
              "11             1              36  \n",
              "12             1              27  \n",
              "13             1               5  \n",
              "14             1              40  \n",
              "15             1              52  \n",
              "16             1               2  \n",
              "17             1              80  \n",
              "18             1              18  \n",
              "19             1               1  \n",
              "20             1              10  "
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pivot table for mean sentiment per ticker (per week) - weeks 1+ (open-ended)\n",
        "weekly_pivot_mean = weekly_stats.pivot(index=\"ticker\", columns=\"week\", values=\"sentiment_mean\")\n",
        "print(\"Mean sentiment per ticker per week (Mondays only, weeks 1+) - pivot view:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Note: Week 0 (dates before 1/12) is excluded. If a ticker has NaN for a week,\")\n",
        "print(\"      that ticker had no articles on the Monday(s) in that week.\")\n",
        "print(\"      Weeks are open-ended; new weeks will appear as data extends past 2/9.\")\n",
        "weekly_pivot_mean\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean sentiment per ticker per week (Mondays only, weeks 1+) - pivot view:\n",
            "================================================================================\n",
            "Note: Week 0 (dates before 1/12) is excluded. If a ticker has NaN for a week,\n",
            "      that ticker had no articles on the Monday(s) in that week.\n",
            "      Weeks are open-ended; new weeks will appear as data extends past 2/9.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>week</th>\n",
              "      <th>1</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ticker</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AAPL</th>\n",
              "      <td>0.233953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>0.140370</td>\n",
              "      <td>-0.190000</td>\n",
              "      <td>0.171714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>0.090000</td>\n",
              "      <td>-0.016667</td>\n",
              "      <td>0.172133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>META</th>\n",
              "      <td>0.016897</td>\n",
              "      <td>0.081000</td>\n",
              "      <td>0.004167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSFT</th>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NVDA</th>\n",
              "      <td>0.364038</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.211875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TSLA</th>\n",
              "      <td>0.087222</td>\n",
              "      <td>-0.910000</td>\n",
              "      <td>0.556000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "week           1         4         5\n",
              "ticker                              \n",
              "AAPL    0.233953  0.000000  0.190857\n",
              "AMZN    0.140370 -0.190000  0.171714\n",
              "GOOGL   0.090000 -0.016667  0.172133\n",
              "META    0.016897  0.081000  0.004167\n",
              "MSFT    0.120000  0.000000  0.136000\n",
              "NVDA    0.364038  0.000000  0.211875\n",
              "TSLA    0.087222 -0.910000  0.556000"
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pivot table for median sentiment per ticker (per week)\n",
        "weekly_pivot_median = weekly_stats.pivot(index=\"ticker\", columns=\"week\", values=\"sentiment_median\")\n",
        "print(\"Median sentiment per ticker per week (Mondays only) - pivot view:\")\n",
        "print(\"=\" * 70)\n",
        "# Display table\n",
        "weekly_pivot_median"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Median sentiment per ticker per week (Mondays only) - pivot view:\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>week</th>\n",
              "      <th>1</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ticker</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AAPL</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>META</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSFT</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NVDA</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TSLA</th>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "week       1     4     5\n",
              "ticker                  \n",
              "AAPL    0.00  0.00  0.00\n",
              "AMZN    0.00  0.00  0.00\n",
              "GOOGL   0.00  0.00  0.00\n",
              "META    0.00  0.00  0.00\n",
              "MSFT    0.00  0.00  0.00\n",
              "NVDA    0.12  0.00  0.00\n",
              "TSLA    0.00 -0.91  0.86"
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Diagnostic: Why is week 3 (1/26) missing?\n",
        "\n",
        "Check if 1/26 exists in the data and why it might not appear as a Monday."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check for 1/26 specifically\n",
        "target_date = pd.Timestamp(\"2026-01-26\")\n",
        "print(f\"Checking date: {target_date.date()} (expected Monday for week 3)\")\n",
        "print(f\"Day of week: {target_date.day_name()} (dayofweek={target_date.dayofweek}, Monday=0)\")\n",
        "\n",
        "# Check if this date exists in daily data\n",
        "has_date = (daily[\"article_date\"].dt.date == target_date.date()).any()\n",
        "print(f\"\\nDate exists in daily data: {has_date}\")\n",
        "\n",
        "if has_date:\n",
        "    date_rows = daily[daily[\"article_date\"].dt.date == target_date.date()]\n",
        "    print(f\"  Rows for {target_date.date()}: {len(date_rows)}\")\n",
        "    print(f\"  Tickers: {sorted(date_rows['ticker'].unique())}\")\n",
        "    print(f\"  Day of week in data: {date_rows['article_date'].dt.day_name().iloc[0]}\")\n",
        "else:\n",
        "    print(f\"\\n  → {target_date.date()} is not in daily data (no articles on this date)\")\n",
        "    print(f\"\\nChecking nearby dates:\")\n",
        "    nearby = daily[\n",
        "        (daily[\"article_date\"] >= target_date - pd.Timedelta(days=3)) &\n",
        "        (daily[\"article_date\"] <= target_date + pd.Timedelta(days=3))\n",
        "    ]\n",
        "    if len(nearby) > 0:\n",
        "        print(nearby[[\"article_date\", \"ticker\"]].drop_duplicates().sort_values(\"article_date\"))\n",
        "    else:\n",
        "        print(\"  No articles within 3 days of 1/26\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (advds)",
      "language": "python",
      "name": "advds"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}