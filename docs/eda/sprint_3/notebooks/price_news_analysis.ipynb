{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Price–News Join Analysis\n",
        "\n",
        "Analyze the GDELT–OHLCV join table: **news on day t → prices on day t+1** (next trading day).  \n",
        "We evaluate and validate the data, then compute mean and median sentiment (and optional price metrics) per ticker per day.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 6,530 rows from gdelt_ohlcv_join.csv\n",
            "Columns: ['seendate', 'url', 'title', 'language', 'domain', 'socialimage', 'company', 'ticker', 'date', 'sentiment_score', 'sentiment_hits', 'sentiment_present', 'article_date', 'price_date', 'next_open', 'next_high', 'next_low', 'next_close', 'next_adj_close', 'next_volume']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Find project root\n",
        "current = Path.cwd()\n",
        "while not (current / \"data\").exists() and current != current.parent:\n",
        "    current = current.parent\n",
        "PROJECT_ROOT = current\n",
        "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
        "INPUT_PATH = PROCESSED_DIR / \"gdelt_ohlcv_join.csv\"\n",
        "\n",
        "df = pd.read_csv(\n",
        "    INPUT_PATH,\n",
        "    parse_dates=[\"seendate\", \"article_date\", \"price_date\"],\n",
        ")\n",
        "# Required for analysis\n",
        "required = [\"sentiment_score\", \"ticker\", \"article_date\", \"price_date\"]\n",
        "missing = [c for c in required if c not in df.columns]\n",
        "assert not missing, f\"Missing columns: {missing}\"\n",
        "print(f\"Loaded {len(df):,} rows from {INPUT_PATH.name}\")\n",
        "print(f\"Columns: {list(df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1A. Alternative Join (Trading-Day Indexed)\n",
        "\n",
        "Alternative approach for comparison:\n",
        "- Use `prices_daily_accumulated.csv` as the left/base table (one row per trading day per ticker).\n",
        "- Left-join `gdelt_articles_with_sentiment.csv` on `ticker` and calendar date.\n",
        "- This keeps the trading-day index intact and attaches any same-day news rows.\n",
        "\n",
        "This is separate from the existing `gdelt_ohlcv_join.csv` logic (`news t -> prices t+1`) and is intended for validation/EDA comparisons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alternative join built:\n",
            "  prices rows (left base): 231\n",
            "  joined rows: 5,837\n",
            "  trading date range: 2025-12-29 -> 2026-02-13\n",
            "  unique (trading_date, ticker) pairs: 231\n",
            "  pairs with >=1 matched article: 167\n",
            "  pairs with 0 matched articles: 64\n",
            "\n",
            "Sample rows from alternative join:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trading_date</th>\n",
              "      <th>ticker</th>\n",
              "      <th>close</th>\n",
              "      <th>seendate</th>\n",
              "      <th>title</th>\n",
              "      <th>sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-12-29</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>273.760010</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-12-29</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>232.070007</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-12-29</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>313.559998</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-12-29</td>\n",
              "      <td>META</td>\n",
              "      <td>658.690002</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-12-29</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>487.100006</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-12-29</td>\n",
              "      <td>NVDA</td>\n",
              "      <td>188.220001</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-12-29</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>459.640015</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-12-30</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>273.079987</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-12-30</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>232.529999</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-12-30</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>313.850006</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2025-12-30</td>\n",
              "      <td>META</td>\n",
              "      <td>665.950012</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2025-12-30</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>487.480011</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2025-12-30</td>\n",
              "      <td>NVDA</td>\n",
              "      <td>187.539993</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2025-12-30</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>454.429993</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2025-12-31</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>271.859985</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2025-12-31</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>230.820007</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2025-12-31</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2025-12-31</td>\n",
              "      <td>META</td>\n",
              "      <td>660.090027</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2025-12-31</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>483.619995</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2025-12-31</td>\n",
              "      <td>NVDA</td>\n",
              "      <td>186.500000</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   trading_date ticker       close seendate title  sentiment_score\n",
              "0    2025-12-29   AAPL  273.760010      NaT   NaN              NaN\n",
              "1    2025-12-29   AMZN  232.070007      NaT   NaN              NaN\n",
              "2    2025-12-29  GOOGL  313.559998      NaT   NaN              NaN\n",
              "3    2025-12-29   META  658.690002      NaT   NaN              NaN\n",
              "4    2025-12-29   MSFT  487.100006      NaT   NaN              NaN\n",
              "5    2025-12-29   NVDA  188.220001      NaT   NaN              NaN\n",
              "6    2025-12-29   TSLA  459.640015      NaT   NaN              NaN\n",
              "7    2025-12-30   AAPL  273.079987      NaT   NaN              NaN\n",
              "8    2025-12-30   AMZN  232.529999      NaT   NaN              NaN\n",
              "9    2025-12-30  GOOGL  313.850006      NaT   NaN              NaN\n",
              "10   2025-12-30   META  665.950012      NaT   NaN              NaN\n",
              "11   2025-12-30   MSFT  487.480011      NaT   NaN              NaN\n",
              "12   2025-12-30   NVDA  187.539993      NaT   NaN              NaN\n",
              "13   2025-12-30   TSLA  454.429993      NaT   NaN              NaN\n",
              "14   2025-12-31   AAPL  271.859985      NaT   NaN              NaN\n",
              "15   2025-12-31   AMZN  230.820007      NaT   NaN              NaN\n",
              "16   2025-12-31  GOOGL  313.000000      NaT   NaN              NaN\n",
              "17   2025-12-31   META  660.090027      NaT   NaN              NaN\n",
              "18   2025-12-31   MSFT  483.619995      NaT   NaN              NaN\n",
              "19   2025-12-31   NVDA  186.500000      NaT   NaN              NaN"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Trading-day indexed left join: prices (left) <- gdelt accumulated\n",
        "prices_path = PROCESSED_DIR / \"prices_daily_accumulated.csv\"\n",
        "gdelt_acc_path = PROCESSED_DIR / \"gdelt_articles_with_sentiment.csv\"\n",
        "\n",
        "prices_left = pd.read_csv(prices_path, parse_dates=[\"date\"])\n",
        "gdelt_acc = pd.read_csv(gdelt_acc_path, parse_dates=[\"seendate\"])\n",
        "\n",
        "# Normalize join keys to calendar day + ticker\n",
        "prices_left[\"trading_date\"] = prices_left[\"date\"].dt.tz_localize(None).dt.normalize()\n",
        "gdelt_acc[\"article_date\"] = pd.to_datetime(gdelt_acc[\"seendate\"], utc=True).dt.tz_localize(None).dt.normalize()\n",
        "\n",
        "prices_left[\"ticker\"] = prices_left[\"ticker\"].astype(str).str.upper().str.strip()\n",
        "gdelt_acc[\"ticker\"] = gdelt_acc[\"ticker\"].astype(str).str.upper().str.strip()\n",
        "\n",
        "alt_join = prices_left.merge(\n",
        "    gdelt_acc,\n",
        "    how=\"left\",\n",
        "    left_on=[\"trading_date\", \"ticker\"],\n",
        "    right_on=[\"article_date\", \"ticker\"],\n",
        "    suffixes=(\"_price\", \"_news\"),\n",
        ")\n",
        "\n",
        "print(\"Alternative join built:\")\n",
        "print(f\"  prices rows (left base): {len(prices_left):,}\")\n",
        "print(f\"  joined rows: {len(alt_join):,}\")\n",
        "print(f\"  trading date range: {prices_left['trading_date'].min().date()} -> {prices_left['trading_date'].max().date()}\")\n",
        "\n",
        "# Coverage diagnostics: how many trading-day x ticker rows have at least one matched article\n",
        "coverage = (\n",
        "    alt_join.groupby([\"trading_date\", \"ticker\"], as_index=False)\n",
        "    .agg(has_news=(\"url\", lambda s: s.notna().any()), article_rows=(\"url\", \"count\"))\n",
        ")\n",
        "\n",
        "print(f\"  unique (trading_date, ticker) pairs: {len(coverage):,}\")\n",
        "print(f\"  pairs with >=1 matched article: {int(coverage['has_news'].sum()):,}\")\n",
        "print(f\"  pairs with 0 matched articles: {int((~coverage['has_news']).sum()):,}\")\n",
        "\n",
        "print(\"\\nSample rows from alternative join:\")\n",
        "display(\n",
        "    alt_join[[\"trading_date\", \"ticker\", \"close\", \"seendate\", \"title\", \"sentiment_score\"]]\n",
        "    .sort_values([\"trading_date\", \"ticker\", \"seendate\"], na_position=\"last\")\n",
        "    .head(20)\n",
        ")\n",
        "\n",
        "# Keep as named object for downstream analysis cells if needed\n",
        "alt_join_df = alt_join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>trading_date</th>\n",
              "      <th>mean_sentiment</th>\n",
              "      <th>median_sentiment</th>\n",
              "      <th>sentiment_count</th>\n",
              "      <th>article_count</th>\n",
              "      <th>next_return</th>\n",
              "      <th>abs_return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2025-12-29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.002484</td>\n",
              "      <td>0.002484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2025-12-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.004468</td>\n",
              "      <td>0.004468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2025-12-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.003127</td>\n",
              "      <td>0.003127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2026-01-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.013837</td>\n",
              "      <td>0.013837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>0.417500</td>\n",
              "      <td>0.38</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>2026-02-09</td>\n",
              "      <td>0.592727</td>\n",
              "      <td>0.96</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>2026-02-10</td>\n",
              "      <td>0.151333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>2026-02-11</td>\n",
              "      <td>0.007895</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>2026-02-12</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>2026-02-13</td>\n",
              "      <td>0.067857</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>231 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    ticker trading_date  mean_sentiment  median_sentiment sentiment_count  \\\n",
              "0     AAPL   2025-12-29             NaN               NaN               0   \n",
              "1     AAPL   2025-12-30             NaN               NaN               0   \n",
              "2     AAPL   2025-12-31             NaN               NaN               0   \n",
              "3     AAPL   2026-01-02             NaN               NaN               0   \n",
              "4     AAPL   2026-01-05        0.417500              0.38               4   \n",
              "..     ...          ...             ...               ...             ...   \n",
              "226   TSLA   2026-02-09        0.592727              0.96              11   \n",
              "227   TSLA   2026-02-10        0.151333              0.00               6   \n",
              "228   TSLA   2026-02-11        0.007895              0.00               8   \n",
              "229   TSLA   2026-02-12        0.030000              0.00               5   \n",
              "230   TSLA   2026-02-13        0.067857              0.00               8   \n",
              "\n",
              "     article_count  next_return  abs_return  \n",
              "0                0    -0.002484    0.002484  \n",
              "1                0    -0.004468    0.004468  \n",
              "2                0    -0.003127    0.003127  \n",
              "3                0    -0.013837    0.013837  \n",
              "4                8     0.000000    0.000000  \n",
              "..             ...          ...         ...  \n",
              "226             11     0.000000    0.000000  \n",
              "227             15     0.000000    0.000000  \n",
              "228             19     0.000000    0.000000  \n",
              "229             27     0.000000    0.000000  \n",
              "230             14     0.000000    0.000000  \n",
              "\n",
              "[231 rows x 8 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged = alt_join_df.sort_values(['ticker', 'trading_date'])\n",
        "\n",
        "# Create next day's close based on each ticker's last close\n",
        "merged['next_close'] = merged.groupby('ticker')['close'].shift(-1)\n",
        "# Calculate next day's return\n",
        "merged['next_return'] = (merged['next_close'] - merged['close']) / merged['close']\n",
        "# Calculate absolute return\n",
        "merged['abs_return'] = merged['next_return'].abs()\n",
        "\n",
        "daily = merged.groupby(['ticker', 'trading_date']).agg(\n",
        "    mean_sentiment=('sentiment_score', 'mean'),\n",
        "    median_sentiment=('sentiment_score', 'median'),\n",
        "    sentiment_count=('sentiment_present', 'sum'),\n",
        "    article_count=('title', 'count'),\n",
        "    next_return=('next_return', 'first'),\n",
        "    abs_return=('abs_return', 'first')\n",
        ").reset_index()\n",
        "daily"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Questions:\n",
        "- Does sentiment predict price direction?\n",
        "- Does sentiment predict volatility?\n",
        "\n",
        "### Approaches:\n",
        "- Sentiment bucket analysis?\n",
        "- News volume effect\n",
        "- Disagreement signal (sentiment range vs abs return)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data evaluation and validation\n",
        "\n",
        "**First objective: validate the matching between prices and news** (join integrity, then schema and coverage)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (6530, 22)\n",
            "\n",
            "Dtypes:\n",
            "seendate             datetime64[us, UTC]\n",
            "url                                  str\n",
            "title                                str\n",
            "language                             str\n",
            "domain                               str\n",
            "socialimage                          str\n",
            "company                              str\n",
            "ticker                               str\n",
            "date                                 str\n",
            "sentiment_score                  float64\n",
            "sentiment_hits                   float64\n",
            "sentiment_present                   bool\n",
            "article_date              datetime64[us]\n",
            "price_date                datetime64[us]\n",
            "next_open                        float64\n",
            "next_high                        float64\n",
            "next_low                         float64\n",
            "next_close                       float64\n",
            "next_adj_close                   float64\n",
            "next_volume                        int64\n",
            "_gap_days                          int64\n",
            "days_to_next                       int64\n",
            "dtype: object\n",
            "\n",
            "Key columns present:\n",
            "  article_date: True\n",
            "  price_date: True\n",
            "  ticker: True\n",
            "  sentiment_score: True\n",
            "  next_close: True\n",
            "  next_volume: True\n"
          ]
        }
      ],
      "source": [
        "# Schema and shape\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nDtypes:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nKey columns present:\")\n",
        "key_cols = [\"article_date\", \"price_date\", \"ticker\", \"sentiment_score\", \"next_close\", \"next_volume\"]\n",
        "for c in key_cols:\n",
        "    print(f\"  {c}: {c in df.columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Validate price–news matching\n",
        "\n",
        "Check that **price_date** is the next trading day after **article_date** and that attached prices match the source OHLCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1) Article date → price date (next trading day)\n",
            "   Rows where price_date ≤ article_date: 0 (expect 0)\n",
            "   ✓ All rows have price_date after article_date\n",
            "\n",
            "   Calendar-day gap (article_date to price_date):\n",
            "_gap_days\n",
            "1    5471\n",
            "2     356\n",
            "3     592\n",
            "4     111\n"
          ]
        }
      ],
      "source": [
        "# 1) price_date must be strictly after article_date (next trading day)\n",
        "df[\"_gap_days\"] = (df[\"price_date\"] - df[\"article_date\"]).dt.days\n",
        "bad_order = (df[\"_gap_days\"] <= 0).sum()\n",
        "print(\"1) Article date → price date (next trading day)\")\n",
        "# Display number of misaligned rows (s/b 0)\n",
        "print(f\"   Rows where price_date ≤ article_date: {bad_order} (expect 0)\")\n",
        "# Unit test for correct matching\n",
        "assert bad_order == 0, \"Every row must have price_date > article_date\"\n",
        "print(\"   ✓ All rows have price_date after article_date\")\n",
        "print(\"\\n   Calendar-day gap (article_date to price_date):\")\n",
        "print(df[\"_gap_days\"].value_counts().sort_index().to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2) One price per (price_date, ticker)\n",
            "   Unique (price_date, ticker) pairs: 176\n",
            "   Pairs with conflicting next_* values: 0 (expect 0)\n",
            "   ✓ All rows for same (price_date, ticker) have identical next_* values\n"
          ]
        }
      ],
      "source": [
        "# 2) Within join: each (price_date, ticker) should have exactly one set of next_* values (no conflicts)\n",
        "price_cols = [c for c in df.columns if c.startswith(\"next_\")]\n",
        "check = df.groupby([\"price_date\", \"ticker\"])[price_cols].nunique()\n",
        "max_per_col = check.max()\n",
        "conflicts = (check > 1).any(axis=1).sum()\n",
        "print(\"2) One price per (price_date, ticker)\")\n",
        "print(f\"   Unique (price_date, ticker) pairs: {len(check):,}\")\n",
        "print(f\"   Pairs with conflicting next_* values: {conflicts} (expect 0)\")\n",
        "# Unit test for unique prices per (price_date, ticker)\n",
        "assert conflicts == 0, \"⚠ Some (price_date, ticker) have multiple different prices — investigate\"\n",
        "print(\"   ✓ All rows for same (price_date, ticker) have identical next_* values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3) Join vs source OHLCV (next_close vs close)\n",
            "   (price_date, ticker) pairs checked: 176\n",
            "   Mismatches (join next_close ≠ OHLCV close): 0\n",
            "   Missing in OHLCV: 0\n",
            "   ✓ All join prices match source OHLCV\n"
          ]
        }
      ],
      "source": [
        "# 3) Cross-check: join next_* values vs source OHLCV (prices_daily_accumulated)\n",
        "ohlcv_path = PROCESSED_DIR / \"prices_daily_accumulated.csv\"\n",
        "if ohlcv_path.exists():\n",
        "    ohlcv = pd.read_csv(ohlcv_path, parse_dates=[\"date\"])\n",
        "    # One row per (date, ticker) in join; take first next_* per (price_date, ticker)\n",
        "    join_prices = df.groupby([\"price_date\", \"ticker\"])[\"next_close\"].first().reset_index()\n",
        "    join_prices = join_prices.rename(columns={\"price_date\": \"date\", \"next_close\": \"join_close\"})\n",
        "    merged = join_prices.merge(ohlcv[[\"date\", \"ticker\", \"close\"]], on=[\"date\", \"ticker\"], how=\"left\")\n",
        "    merged[\"match\"] = merged[\"join_close\"].round(6) == merged[\"close\"].round(6)\n",
        "    mismatches = (~merged[\"match\"]).sum()\n",
        "    missing = merged[\"close\"].isna().sum()\n",
        "    print(\"3) Join vs source OHLCV (next_close vs close)\")\n",
        "    print(f\"   (price_date, ticker) pairs checked: {len(merged):,}\")\n",
        "    print(f\"   Mismatches (join next_close ≠ OHLCV close): {mismatches}\")\n",
        "    print(f\"   Missing in OHLCV: {missing}\")\n",
        "    # Unit test for matching prices\n",
        "    assert mismatches == 0 and missing == 0, \"   ⚠ Review mismatches or missing dates\"\n",
        "    print(\"   ✓ All join prices match source OHLCV\")\n",
        "else:\n",
        "    print(\"3) Skip cross-check (prices_daily_accumulated.csv not found)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Schema, date ranges, and coverage\n",
        "\n",
        "Schema, date ranges, missing values, and ticker coverage (for downstream aggregation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Article date range: 2026-01-05 to 2026-02-12\n",
            "Price date range:  2026-01-06 to 2026-02-13\n",
            "\n",
            "Expected: price_date = next trading day after article_date (weekends/holidays skipped).\n",
            "\n",
            "Calendar days from article_date to price_date (sample):\n",
            "days_to_next\n",
            "1    5471\n",
            "3     592\n",
            "2     356\n",
            "4     111\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Date ranges and join alignment\n",
        "art_min, art_max = df[\"article_date\"].min(), df[\"article_date\"].max()\n",
        "price_min, price_max = df[\"price_date\"].min(), df[\"price_date\"].max()\n",
        "print(\"Article date range:\", art_min.date(), \"to\", art_max.date())\n",
        "print(\"Price date range: \", price_min.date(), \"to\", price_max.date())\n",
        "print(\"\\nExpected: price_date = next trading day after article_date (weekends/holidays skipped).\")\n",
        "# Spot-check: article_date and price_date should differ by 1–3 calendar days (Fri→Mon = 3)\n",
        "df[\"days_to_next\"] = (df[\"price_date\"] - df[\"article_date\"]).dt.days\n",
        "print(\"\\nCalendar days from article_date to price_date (sample):\")\n",
        "print(df[\"days_to_next\"].value_counts().head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values (columns used for mean/median per ticker per day):\n",
            "  None\n",
            "\n",
            "Rows with any missing in these columns: 0\n"
          ]
        }
      ],
      "source": [
        "# Missing values in columns used for aggregation\n",
        "agg_cols = [\"sentiment_score\", \"ticker\", \"article_date\", \"price_date\"]\n",
        "if \"next_close\" in df.columns:\n",
        "    agg_cols.append(\"next_close\")\n",
        "missing = df[agg_cols].isna().sum()\n",
        "print(\"Missing values (columns used for mean/median per ticker per day):\")\n",
        "print(missing[missing > 0] if missing.any() else \"  None\")\n",
        "print(\"\\nRows with any missing in these columns:\", df[agg_cols].isna().any(axis=1).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Articles per ticker:\n",
            "ticker\n",
            "AAPL      700\n",
            "AMZN      745\n",
            "GOOGL    1277\n",
            "META     1112\n",
            "MSFT      729\n",
            "NVDA     1462\n",
            "TSLA      505\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique (article_date, ticker) pairs per ticker = distinct calendar days with ≥1 article:\n",
            "ticker\n",
            "AAPL     27\n",
            "AMZN     30\n",
            "GOOGL    36\n",
            "META     36\n",
            "MSFT     26\n",
            "NVDA     28\n",
            "TSLA     30\n",
            "\n",
            "(Multiple articles per day per ticker is expected; we aggregate to mean/median per (date, ticker) later.)\n"
          ]
        }
      ],
      "source": [
        "# Ticker coverage: articles and (article_date, ticker) pairs\n",
        "print(\"Articles per ticker:\")\n",
        "print(df[\"ticker\"].value_counts().sort_index())\n",
        "print(\"\\nUnique (article_date, ticker) pairs per ticker = distinct calendar days with ≥1 article:\")\n",
        "# Per ticker, count distinct article_date (same as count of (article_date, ticker) per ticker)\n",
        "unique_days_per_ticker = df.groupby(\"ticker\")[\"article_date\"].nunique()\n",
        "print(unique_days_per_ticker.to_string())\n",
        "print(\"\\n(Multiple articles per day per ticker is expected; we aggregate to mean/median per (date, ticker) later.)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mean and median sentiment per ticker per day:\n",
            "                       mean  median\n",
            "ticker price_date                  \n",
            "AAPL   2026-01-06  0.417500    0.38\n",
            "       2026-01-07  0.262857    0.00\n",
            "       2026-01-08  0.052500    0.00\n",
            "       2026-01-12  0.317308    0.00\n",
            "       2026-01-13  0.230213    0.00\n"
          ]
        }
      ],
      "source": [
        "# Compute mean/median sentiment per ticker per day\n",
        "sentiment_per_ticker_per_day = df.groupby([\"ticker\", \"price_date\"])[\"sentiment_score\"].agg([\"mean\", \"median\"])\n",
        "print(\"\\nMean and median sentiment per ticker per day:\")\n",
        "print(sentiment_per_ticker_per_day.head())\n",
        "\n",
        "# Sanity check aggregated outputs across tickers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sentiment summary statistics per ticker per day\n",
        "\n",
        "Aggregate to mean and median sentiment per (ticker, day)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Daily summary (first rows):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_date</th>\n",
              "      <th>ticker</th>\n",
              "      <th>sentiment_mean</th>\n",
              "      <th>sentiment_median</th>\n",
              "      <th>article_count</th>\n",
              "      <th>next_close</th>\n",
              "      <th>next_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.417500</td>\n",
              "      <td>0.38</td>\n",
              "      <td>8</td>\n",
              "      <td>262.359985</td>\n",
              "      <td>52352100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.38</td>\n",
              "      <td>2</td>\n",
              "      <td>240.929993</td>\n",
              "      <td>53764700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.91</td>\n",
              "      <td>2</td>\n",
              "      <td>314.339996</td>\n",
              "      <td>31212100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>0.006667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6</td>\n",
              "      <td>478.510010</td>\n",
              "      <td>23037700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>NVDA</td>\n",
              "      <td>0.411429</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7</td>\n",
              "      <td>187.240005</td>\n",
              "      <td>176862600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2026-01-05</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>432.959991</td>\n",
              "      <td>89093800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2026-01-06</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.262857</td>\n",
              "      <td>0.00</td>\n",
              "      <td>21</td>\n",
              "      <td>260.329987</td>\n",
              "      <td>48309800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2026-01-06</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>0.206923</td>\n",
              "      <td>0.00</td>\n",
              "      <td>52</td>\n",
              "      <td>241.559998</td>\n",
              "      <td>42236500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2026-01-06</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>0.490769</td>\n",
              "      <td>0.76</td>\n",
              "      <td>13</td>\n",
              "      <td>321.980011</td>\n",
              "      <td>35104400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2026-01-06</td>\n",
              "      <td>META</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>16</td>\n",
              "      <td>648.690002</td>\n",
              "      <td>12846300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  article_date ticker  sentiment_mean  sentiment_median  article_count  \\\n",
              "0   2026-01-05   AAPL        0.417500              0.38              8   \n",
              "1   2026-01-05   AMZN        0.380000              0.38              2   \n",
              "2   2026-01-05  GOOGL        0.910000              0.91              2   \n",
              "3   2026-01-05   MSFT        0.006667              0.00              6   \n",
              "4   2026-01-05   NVDA        0.411429              0.00              7   \n",
              "5   2026-01-05   TSLA        0.066667              0.00              3   \n",
              "6   2026-01-06   AAPL        0.262857              0.00             21   \n",
              "7   2026-01-06   AMZN        0.206923              0.00             52   \n",
              "8   2026-01-06  GOOGL        0.490769              0.76             13   \n",
              "9   2026-01-06   META        0.125000              0.00             16   \n",
              "\n",
              "   next_close  next_volume  \n",
              "0  262.359985     52352100  \n",
              "1  240.929993     53764700  \n",
              "2  314.339996     31212100  \n",
              "3  478.510010     23037700  \n",
              "4  187.240005    176862600  \n",
              "5  432.959991     89093800  \n",
              "6  260.329987     48309800  \n",
              "7  241.559998     42236500  \n",
              "8  321.980011     35104400  \n",
              "9  648.690002     12846300  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Aggregate: one row per (article_date, ticker)\n",
        "daily = df.groupby([\"article_date\", \"ticker\"]).agg(\n",
        "    sentiment_mean=(\"sentiment_score\", \"mean\"),\n",
        "    sentiment_median=(\"sentiment_score\", \"median\"),\n",
        "    article_count=(\"sentiment_score\", \"count\"),\n",
        ").reset_index()\n",
        "if \"next_close\" in df.columns:\n",
        "    daily[\"next_close\"] = df.groupby([\"article_date\", \"ticker\"])[\"next_close\"].first().values\n",
        "if \"next_volume\" in df.columns:\n",
        "    daily[\"next_volume\"] = df.groupby([\"article_date\", \"ticker\"])[\"next_volume\"].first().values\n",
        "\n",
        "print(\"Daily summary (first rows):\")\n",
        "daily.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Monday-only analysis: sentiment per ticker per week\n",
        "\n",
        "Filter to **Mondays only** (article_date), then group by week (7-day increments starting from **2026-01-12** as week 1). Compute summary statistics per ticker per week (open-ended; weeks 1+)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rows: 213\n",
            "Mondays only: 41 (19.2%)\n",
            "\n",
            "Monday dates in data:\n",
            "[datetime.date(2026, 1, 5), datetime.date(2026, 1, 12), datetime.date(2026, 1, 19), datetime.date(2026, 1, 26), datetime.date(2026, 2, 2), datetime.date(2026, 2, 9)]\n",
            "\n",
            "Expected Mondays (if all weeks present):\n",
            "  Week 1: 2026-01-12\n",
            "  Week 2: 2026-01-19\n",
            "  Week 3: 2026-01-26\n",
            "  Week 4: 2026-02-02\n",
            "  Week 5: 2026-02-09\n"
          ]
        }
      ],
      "source": [
        "# Filter to Mondays only (dayofweek: Monday=0)\n",
        "mondays = daily[daily[\"article_date\"].dt.dayofweek == 0].copy()\n",
        "print(f\"Total rows: {len(daily):,}\")\n",
        "print(f\"Mondays only: {len(mondays):,} ({100*len(mondays)/len(daily):.1f}%)\")\n",
        "print(f\"\\nMonday dates in data:\")\n",
        "monday_dates = sorted(mondays[\"article_date\"].dt.date.unique())\n",
        "print(monday_dates)\n",
        "print(f\"\\nExpected Mondays (if all weeks present):\")\n",
        "week_start = pd.Timestamp(\"2026-01-12\")\n",
        "for w in range(1, 6):  # weeks 1-5 based on data up to 2/9\n",
        "    expected_monday = week_start + pd.Timedelta(days=7*(w-1))\n",
        "    print(f\"  Week {w}: {expected_monday.date()}\")\n",
        "    if expected_monday.date() not in monday_dates:\n",
        "        print(f\"    ⚠ MISSING from data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: MLK holiday on 1/19 causes week 2 to be missing\n",
            "Week start date: 2026-01-12\n",
            "Week range in data: 1 to 5 (open-ended)\n",
            "\n",
            "Mondays per week:\n",
            "week\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "5    1\n",
            "Name: article_date, dtype: int64\n",
            "\n",
            "Missing weeks (expected but not present):\n",
            "  None\n"
          ]
        }
      ],
      "source": [
        "# Assign week number (increments of 7 days starting from 2026-01-12)\n",
        "# Week 1 = 2026-01-12 + 0-6 days, Week 2 = 2026-01-12 + 7-13 days, etc.\n",
        "week_start_date = pd.Timestamp(\"2026-01-12\")\n",
        "mondays[\"days_since_week1_start\"] = (mondays[\"article_date\"] - week_start_date).dt.days\n",
        "mondays[\"week\"] = (mondays[\"days_since_week1_start\"] // 7) + 1\n",
        "# Explain missing weeks (MLK holiday on 1/19)\n",
        "print(\"Note: MLK holiday on 1/19 causes week 2 to be missing\")\n",
        "# Filter to weeks >= 1 (exclude dates before 1/12, but no upper limit - open-ended)\n",
        "mondays_filtered = mondays[mondays[\"week\"] >= 1].copy()\n",
        "print(f\"Week start date: {week_start_date.date()}\")\n",
        "print(f\"Week range in data: {mondays_filtered['week'].min()} to {mondays_filtered['week'].max()} (open-ended)\")\n",
        "print(f\"\\nMondays per week:\")\n",
        "week_counts = mondays_filtered.groupby(\"week\")[\"article_date\"].nunique()\n",
        "print(week_counts)\n",
        "print(f\"\\nMissing weeks (expected but not present):\")\n",
        "all_weeks = set(range(mondays_filtered['week'].min(), mondays_filtered['week'].max() + 1))\n",
        "present_weeks = set(week_counts.index)\n",
        "missing_weeks = sorted(all_weeks - present_weeks)\n",
        "if missing_weeks:\n",
        "    for w in missing_weeks:\n",
        "        expected_date = week_start_date + pd.Timedelta(days=7*(w-1))\n",
        "        print(f\"  Week {w}: {expected_date.date()} (no articles on this Monday)\")\n",
        "        # Check if this date exists in the raw daily data (not just Mondays)\n",
        "        if expected_date.date() in daily[\"article_date\"].dt.date.values:\n",
        "            print(f\"    → Date exists in daily data but is not a Monday (dayofweek check)\")\n",
        "        else:\n",
        "            print(f\"    → Date not in daily data at all (no articles on this date)\")\n",
        "else:\n",
        "    print(\"  None\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary statistics per ticker per week (Mondays only, weeks 1+):\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>week</th>\n",
              "      <th>sentiment_mean</th>\n",
              "      <th>sentiment_median</th>\n",
              "      <th>monday_count</th>\n",
              "      <th>total_articles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.230213</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "      <td>0.008947</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "      <td>0.212051</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>5</td>\n",
              "      <td>0.180541</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.184828</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>2</td>\n",
              "      <td>0.071600</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>3</td>\n",
              "      <td>0.120217</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.190000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>5</td>\n",
              "      <td>0.171714</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GOOGL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.110455</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>GOOGL</td>\n",
              "      <td>2</td>\n",
              "      <td>0.137143</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>GOOGL</td>\n",
              "      <td>3</td>\n",
              "      <td>0.224483</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>GOOGL</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.016667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>GOOGL</td>\n",
              "      <td>5</td>\n",
              "      <td>0.148986</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>META</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000968</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>META</td>\n",
              "      <td>2</td>\n",
              "      <td>0.350769</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>META</td>\n",
              "      <td>3</td>\n",
              "      <td>0.054074</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>META</td>\n",
              "      <td>4</td>\n",
              "      <td>0.083793</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>META</td>\n",
              "      <td>5</td>\n",
              "      <td>0.024571</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.024211</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>2</td>\n",
              "      <td>0.199565</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>3</td>\n",
              "      <td>0.193191</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>5</td>\n",
              "      <td>0.136000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>1</td>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>2</td>\n",
              "      <td>0.185909</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>3</td>\n",
              "      <td>0.313163</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>5</td>\n",
              "      <td>0.206707</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>1</td>\n",
              "      <td>0.098125</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>2</td>\n",
              "      <td>0.330909</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>3</td>\n",
              "      <td>0.224000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.910000</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>5</td>\n",
              "      <td>0.592727</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ticker  week  sentiment_mean  sentiment_median  monday_count  \\\n",
              "0    AAPL     1        0.230213              0.00             1   \n",
              "1    AAPL     2        0.008947              0.00             1   \n",
              "2    AAPL     3        0.212051              0.00             1   \n",
              "3    AAPL     4        0.000000              0.00             1   \n",
              "4    AAPL     5        0.180541              0.00             1   \n",
              "5    AMZN     1        0.184828              0.00             1   \n",
              "6    AMZN     2        0.071600              0.00             1   \n",
              "7    AMZN     3        0.120217              0.00             1   \n",
              "8    AMZN     4       -0.190000              0.00             1   \n",
              "9    AMZN     5        0.171714              0.00             1   \n",
              "10  GOOGL     1        0.110455              0.00             1   \n",
              "11  GOOGL     2        0.137143              0.00             1   \n",
              "12  GOOGL     3        0.224483              0.00             1   \n",
              "13  GOOGL     4       -0.016667              0.00             1   \n",
              "14  GOOGL     5        0.148986              0.00             1   \n",
              "15   META     1        0.000968              0.00             1   \n",
              "16   META     2        0.350769              0.00             1   \n",
              "17   META     3        0.054074              0.00             1   \n",
              "18   META     4        0.083793              0.00             1   \n",
              "19   META     5        0.024571              0.00             1   \n",
              "20   MSFT     1       -0.024211              0.00             1   \n",
              "21   MSFT     2        0.199565              0.00             1   \n",
              "22   MSFT     3        0.193191              0.00             1   \n",
              "23   MSFT     4        0.000000              0.00             1   \n",
              "24   MSFT     5        0.136000              0.00             1   \n",
              "25   NVDA     1        0.370000              0.12             1   \n",
              "26   NVDA     2        0.185909              0.00             1   \n",
              "27   NVDA     3        0.313163              0.00             1   \n",
              "28   NVDA     4        0.000000              0.00             1   \n",
              "29   NVDA     5        0.206707              0.00             1   \n",
              "30   TSLA     1        0.098125              0.00             1   \n",
              "31   TSLA     2        0.330909              0.00             1   \n",
              "32   TSLA     3        0.224000              0.00             1   \n",
              "33   TSLA     4       -0.910000             -0.91             1   \n",
              "34   TSLA     5        0.592727              0.96             1   \n",
              "\n",
              "    total_articles  \n",
              "0               47  \n",
              "1               19  \n",
              "2               39  \n",
              "3                1  \n",
              "4               37  \n",
              "5               29  \n",
              "6               25  \n",
              "7               46  \n",
              "8                4  \n",
              "9               35  \n",
              "10              22  \n",
              "11              14  \n",
              "12              29  \n",
              "13               3  \n",
              "14              69  \n",
              "15              31  \n",
              "16              13  \n",
              "17              27  \n",
              "18              29  \n",
              "19              35  \n",
              "20              19  \n",
              "21              23  \n",
              "22              47  \n",
              "23               5  \n",
              "24              40  \n",
              "25              54  \n",
              "26              44  \n",
              "27              98  \n",
              "28               2  \n",
              "29              82  \n",
              "30              16  \n",
              "31              11  \n",
              "32              20  \n",
              "33               1  \n",
              "34              11  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary statistics per ticker per week (Mondays only)\n",
        "# Use mondays_filtered to exclude week 0 (dates before 1/12)\n",
        "weekly_stats = mondays_filtered.groupby([\"ticker\", \"week\"]).agg(\n",
        "    sentiment_mean=(\"sentiment_mean\", \"mean\"),\n",
        "    sentiment_median=(\"sentiment_median\", \"median\"),\n",
        "    # sentiment_std excluded: std of already-aggregated daily means is problematic (NaN when only one Monday)\n",
        "    monday_count=(\"article_date\", \"nunique\"),  # number of Mondays in this week with data\n",
        "    total_articles=(\"article_count\", \"sum\"),\n",
        ").reset_index()\n",
        "\n",
        "print(\"Summary statistics per ticker per week (Mondays only, weeks 1+):\")\n",
        "print(\"=\" * 80)\n",
        "weekly_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean sentiment per ticker per week (Mondays only, weeks 1+) - pivot view:\n",
            "================================================================================\n",
            "Note: Week 0 (dates before 1/12) is excluded. If a ticker has NaN for a week,\n",
            "      that ticker had no articles on the Monday(s) in that week.\n",
            "      Weeks are open-ended; new weeks will appear as data extends past 2/9.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>week</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ticker</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AAPL</th>\n",
              "      <td>0.230213</td>\n",
              "      <td>0.008947</td>\n",
              "      <td>0.212051</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.180541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>0.184828</td>\n",
              "      <td>0.071600</td>\n",
              "      <td>0.120217</td>\n",
              "      <td>-0.190000</td>\n",
              "      <td>0.171714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>0.110455</td>\n",
              "      <td>0.137143</td>\n",
              "      <td>0.224483</td>\n",
              "      <td>-0.016667</td>\n",
              "      <td>0.148986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>META</th>\n",
              "      <td>0.000968</td>\n",
              "      <td>0.350769</td>\n",
              "      <td>0.054074</td>\n",
              "      <td>0.083793</td>\n",
              "      <td>0.024571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSFT</th>\n",
              "      <td>-0.024211</td>\n",
              "      <td>0.199565</td>\n",
              "      <td>0.193191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NVDA</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.185909</td>\n",
              "      <td>0.313163</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TSLA</th>\n",
              "      <td>0.098125</td>\n",
              "      <td>0.330909</td>\n",
              "      <td>0.224000</td>\n",
              "      <td>-0.910000</td>\n",
              "      <td>0.592727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "week           1         2         3         4         5\n",
              "ticker                                                  \n",
              "AAPL    0.230213  0.008947  0.212051  0.000000  0.180541\n",
              "AMZN    0.184828  0.071600  0.120217 -0.190000  0.171714\n",
              "GOOGL   0.110455  0.137143  0.224483 -0.016667  0.148986\n",
              "META    0.000968  0.350769  0.054074  0.083793  0.024571\n",
              "MSFT   -0.024211  0.199565  0.193191  0.000000  0.136000\n",
              "NVDA    0.370000  0.185909  0.313163  0.000000  0.206707\n",
              "TSLA    0.098125  0.330909  0.224000 -0.910000  0.592727"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pivot table for mean sentiment per ticker (per week) - weeks 1+ (open-ended)\n",
        "weekly_pivot_mean = weekly_stats.pivot(index=\"ticker\", columns=\"week\", values=\"sentiment_mean\")\n",
        "print(\"Mean sentiment per ticker per week (Mondays only, weeks 1+) - pivot view:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Note: Week 0 (dates before 1/12) is excluded. If a ticker has NaN for a week,\")\n",
        "print(\"      that ticker had no articles on the Monday(s) in that week.\")\n",
        "print(\"      Weeks are open-ended; new weeks will appear as data extends past 2/9.\")\n",
        "weekly_pivot_mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Median sentiment per ticker per week (Mondays only) - pivot view:\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>week</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ticker</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AAPL</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>META</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSFT</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NVDA</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TSLA</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "week       1    2    3     4     5\n",
              "ticker                            \n",
              "AAPL    0.00  0.0  0.0  0.00  0.00\n",
              "AMZN    0.00  0.0  0.0  0.00  0.00\n",
              "GOOGL   0.00  0.0  0.0  0.00  0.00\n",
              "META    0.00  0.0  0.0  0.00  0.00\n",
              "MSFT    0.00  0.0  0.0  0.00  0.00\n",
              "NVDA    0.12  0.0  0.0  0.00  0.00\n",
              "TSLA    0.00  0.0  0.0 -0.91  0.96"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pivot table for median sentiment per ticker (per week)\n",
        "weekly_pivot_median = weekly_stats.pivot(index=\"ticker\", columns=\"week\", values=\"sentiment_median\")\n",
        "print(\"Median sentiment per ticker per week (Mondays only) - pivot view:\")\n",
        "print(\"=\" * 70)\n",
        "# Display table\n",
        "weekly_pivot_median"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (advds)",
      "language": "python",
      "name": "advds"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
