{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDELT Data Validation\n",
    "\n",
    "This notebook validates the GDELT news articles data ingested for MAG7 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1,400 rows from ../data/raw/gdelt_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "# Load the GDELT articles data\n",
    "DATA_PATH = Path(\"../data/raw/gdelt_articles.csv\")\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"seendate\"])\n",
    "print(f\"Loaded {len(df):,} rows from {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = DATA_PATH.parent                    # ../data/raw\n",
    "PROCESSED_DIR = DATA_PATH.parent.parent / \"processed\"  # ../data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build output filename from input\n",
    "output_filename = DATA_PATH.stem + \"_clean.csv\"  # gdelt_articles_clean.csv\n",
    "output_path = PROCESSED_DIR / output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_rows = len(df)\n",
    "original_cols = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>seendate</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>domain</th>\n",
       "      <th>sourceCountry</th>\n",
       "      <th>socialimage</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"Apple\" OR AAPL) (stock OR shares OR earnings...</td>\n",
       "      <td>2026-01-13 15:00:00+00:00</td>\n",
       "      <td>https://smartmania.cz/po-letech-zmena-krale-ap...</td>\n",
       "      <td>Po letech změna krále : Apple prodal víc telef...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Czech</td>\n",
       "      <td>smartmania.cz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://smartmania.cz/wp-content/uploads/2025/...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"Apple\" OR AAPL) (stock OR shares OR earnings...</td>\n",
       "      <td>2026-01-13 15:00:00+00:00</td>\n",
       "      <td>https://www.sej.org/headlines/trump-s-biggest-...</td>\n",
       "      <td>Trump Biggest Inaugural Donor Benefits from Wo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>sej.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"Apple\" OR AAPL) (stock OR shares OR earnings...</td>\n",
       "      <td>2026-01-13 15:00:00+00:00</td>\n",
       "      <td>https://finance.yahoo.com/news/prediction-spec...</td>\n",
       "      <td>Prediction : This Spectacular Vanguard ETF Wil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>finance.yahoo.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s.yimg.com/ny/api/res/1.2/vPftkj6hH9si...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(\"Apple\" OR AAPL) (stock OR shares OR earnings...</td>\n",
       "      <td>2026-01-13 15:00:00+00:00</td>\n",
       "      <td>https://www.proactiveinvestors.com/companies/n...</td>\n",
       "      <td>S &amp; P and Nasdaq hold as Dow starts lower desp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>proactiveinvestors.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cdn.proactiveinvestors.com/eyJidWNrZXQ...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(\"Apple\" OR AAPL) (stock OR shares OR earnings...</td>\n",
       "      <td>2026-01-13 14:45:00+00:00</td>\n",
       "      <td>http://www.thailandnews.net/news/278802381/aut...</td>\n",
       "      <td>Auto industry bets on AI partnerships after co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>thailandnews.net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://image.chitra.live/api/v1/wps/ed80633/b...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  (\"Apple\" OR AAPL) (stock OR shares OR earnings...   \n",
       "1  (\"Apple\" OR AAPL) (stock OR shares OR earnings...   \n",
       "2  (\"Apple\" OR AAPL) (stock OR shares OR earnings...   \n",
       "3  (\"Apple\" OR AAPL) (stock OR shares OR earnings...   \n",
       "4  (\"Apple\" OR AAPL) (stock OR shares OR earnings...   \n",
       "\n",
       "                   seendate  \\\n",
       "0 2026-01-13 15:00:00+00:00   \n",
       "1 2026-01-13 15:00:00+00:00   \n",
       "2 2026-01-13 15:00:00+00:00   \n",
       "3 2026-01-13 15:00:00+00:00   \n",
       "4 2026-01-13 14:45:00+00:00   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://smartmania.cz/po-letech-zmena-krale-ap...   \n",
       "1  https://www.sej.org/headlines/trump-s-biggest-...   \n",
       "2  https://finance.yahoo.com/news/prediction-spec...   \n",
       "3  https://www.proactiveinvestors.com/companies/n...   \n",
       "4  http://www.thailandnews.net/news/278802381/aut...   \n",
       "\n",
       "                                               title  description language  \\\n",
       "0  Po letech změna krále : Apple prodal víc telef...          NaN    Czech   \n",
       "1  Trump Biggest Inaugural Donor Benefits from Wo...          NaN  English   \n",
       "2  Prediction : This Spectacular Vanguard ETF Wil...          NaN  English   \n",
       "3  S & P and Nasdaq hold as Dow starts lower desp...          NaN  English   \n",
       "4  Auto industry bets on AI partnerships after co...          NaN  English   \n",
       "\n",
       "                   domain  sourceCountry  \\\n",
       "0           smartmania.cz            NaN   \n",
       "1                 sej.org            NaN   \n",
       "2       finance.yahoo.com            NaN   \n",
       "3  proactiveinvestors.com            NaN   \n",
       "4        thailandnews.net            NaN   \n",
       "\n",
       "                                         socialimage company ticker  \n",
       "0  https://smartmania.cz/wp-content/uploads/2025/...   Apple   AAPL  \n",
       "1                                                NaN   Apple   AAPL  \n",
       "2  https://s.yimg.com/ny/api/res/1.2/vPftkj6hH9si...   Apple   AAPL  \n",
       "3  https://cdn.proactiveinvestors.com/eyJidWNrZXQ...   Apple   AAPL  \n",
       "4  https://image.chitra.live/api/v1/wps/ed80633/b...   Apple   AAPL  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #how many rows and columns we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'seendate', 'url', 'title', 'description', 'language',\n",
       "       'domain', 'sourceCountry', 'socialimage', 'company', 'ticker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check all column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1400 entries, 0 to 1399\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   query          1400 non-null   object             \n",
      " 1   seendate       1400 non-null   datetime64[ns, UTC]\n",
      " 2   url            1400 non-null   object             \n",
      " 3   title          1400 non-null   object             \n",
      " 4   description    0 non-null      float64            \n",
      " 5   language       1400 non-null   object             \n",
      " 6   domain         1400 non-null   object             \n",
      " 7   sourceCountry  0 non-null      float64            \n",
      " 8   socialimage    1168 non-null   object             \n",
      " 9   company        1400 non-null   object             \n",
      " 10  ticker         1400 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), object(8)\n",
      "memory usage: 120.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#check if any comand is null, missing or useful\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query               0\n",
       "seendate            0\n",
       "url                 0\n",
       "title               0\n",
       "description      1400\n",
       "language            0\n",
       "domain              0\n",
       "sourceCountry    1400\n",
       "socialimage       232\n",
       "company             0\n",
       "ticker              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #count all the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query              0.000000\n",
       "seendate           0.000000\n",
       "url                0.000000\n",
       "title              0.000000\n",
       "description      100.000000\n",
       "language           0.000000\n",
       "domain             0.000000\n",
       "sourceCountry    100.000000\n",
       "socialimage       16.571429\n",
       "company            0.000000\n",
       "ticker             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many percentage of missing values we have based on the whole dataset\n",
    "\n",
    "(df.isnull().sum()/len(df)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can see that all description and sourceCountry data are missing, and socialimage missed 14% of the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (1400, 11)\n",
      "After: (1400, 9)\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.drop(columns=['description', 'sourceCountry'])\n",
    "print(f\"Before: {df.shape}\")\n",
    "print(f\"After: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 1050\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Duplicate rows: {df_clean.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate URL: 1169\n",
      "\n",
      "Rows with duplicated urls: 1400\n",
      "One example of duplicated urls:\n",
      "                                                   url company ticker\n",
      "0    https://smartmania.cz/po-letech-zmena-krale-ap...   Apple   AAPL\n",
      "50   https://smartmania.cz/po-letech-zmena-krale-ap...   Apple   AAPL\n",
      "100  https://smartmania.cz/po-letech-zmena-krale-ap...   Apple   AAPL\n",
      "150  https://smartmania.cz/po-letech-zmena-krale-ap...   Apple   AAPL\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicate URL: {df_clean['url'].duplicated().sum()}\")\n",
    "\n",
    "duplicated_urls = df_clean[df_clean['url'].duplicated(keep=False)]\n",
    "print(f\"\\nRows with duplicated urls: {len(duplicated_urls)}\")\n",
    "\n",
    "print(f\"One example of duplicated urls:\")\n",
    "example_url = duplicated_urls['url'].iloc[0]\n",
    "print(df_clean[df_clean['url'] == example_url] [['url', 'company', 'ticker']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after removing duplicates: 350\n",
      "Unique URLs: 231\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_clean.drop_duplicates(subset=['url', 'company'], keep='first')\n",
    "\n",
    "print(f\"Rows after removing duplicates: {len(df_clean):,}\")\n",
    "print(f\"Unique URLs: {df_clean['url'].nunique():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest article: 2026-01-13 03:45:00+00:00\n",
      "Latest article: 2026-01-13 15:00:00+00:00\n",
      "Date span: 0 days\n"
     ]
    }
   ],
   "source": [
    "print(f\"Earliest article: {df_clean['seendate'].min()}\")\n",
    "print(f\"Latest article: {df_clean['seendate'].max()}\")\n",
    "\n",
    "#Calculate the span \n",
    "date_range = df_clean['seendate'].max() - df_clean['seendate'].min()\n",
    "print(f\"Date span: {date_range.days} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty titles: 0\n"
     ]
    }
   ],
   "source": [
    "#Check for empty or short title\n",
    "empty_titles = df_clean['title'].isna().sum()\n",
    "print(f\"Empty titles: {empty_titles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very short titles (<10 chars): 0\n"
     ]
    }
   ],
   "source": [
    "short_titles = (df_clean['title'].str.len() < 10).sum()\n",
    "print(f\"Very short titles (<10 chars): {short_titles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if short_titles > 0:\n",
    "    print(\"\\nShort titles found:\")\n",
    "    print(df_clean[df_clean['title'].str.len() < 10]['title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language in data:\n",
      "language\n",
      "English       298\n",
      "Chinese        16\n",
      "French          6\n",
      "German          5\n",
      "Turkish         4\n",
      "Spanish         4\n",
      "Czech           3\n",
      "Polish          3\n",
      "Hebrew          2\n",
      "Portuguese      2\n",
      "Norwegian       1\n",
      "Vietnamese      1\n",
      "Italian         1\n",
      "Korean          1\n",
      "Romanian        1\n",
      "Thai            1\n",
      "Arabic          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rows after filtering to English: 298\n"
     ]
    }
   ],
   "source": [
    "print(\"Language in data:\")\n",
    "print(df_clean['language'].value_counts())\n",
    "\n",
    "#keep only english\n",
    "df_clean = df_clean[df_clean['language'] == 'English']\n",
    "print(f\"\\nRows after filtering to English: {len(df_clean)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles per company:\n",
      "company\n",
      "Meta Platforms    48\n",
      "Alphabet          46\n",
      "NVIDIA            43\n",
      "Amazon            43\n",
      "Microsoft         41\n",
      "Tesla             41\n",
      "Apple             36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Articles per company:\")\n",
    "print(df_clean['company'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All URLs valid: True\n"
     ]
    }
   ],
   "source": [
    "valid_urls = df_clean['url'].str.startswith(('http://', 'https://')).all()\n",
    "print(f\"All URLs valid: {valid_urls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid URLs: 0\n"
     ]
    }
   ],
   "source": [
    "invalid = df_clean[~df_clean['url'].str.startswith(('http://', 'https://'))]\n",
    "print(f\"Invalid URLs: {len(invalid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 domains:\n",
      "domain\n",
      "finance.yahoo.com     25\n",
      "forbes.com            15\n",
      "zerohedge.com         12\n",
      "insidermonkey.com      9\n",
      "webpronews.com         8\n",
      "abcnews.go.com         8\n",
      "cnbc.com               7\n",
      "afghanistansun.com     6\n",
      "cincinnatisun.com      6\n",
      "thailandnews.net       6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Top 10 news sources - check for source bias\n",
    "print(\"Top 10 domains:\")\n",
    "print(df_clean['domain'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique domains: 115\n"
     ]
    }
   ],
   "source": [
    "# How many unique sources?\n",
    "print(f\"\\nUnique domains: {df_clean['domain'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some articles might not actually be about the company's stock/business:\n",
    "financial_keywords = [\n",
    "    # Stock & Trading\n",
    "    'stock', 'share', 'shares', 'trading', 'trader', 'nasdaq', 'nyse', \n",
    "    's&p', 'dow', 'index', 'etf', 'fund', 'hedge',\n",
    "    \n",
    "    # Financial Metrics\n",
    "    'earnings', 'revenue', 'profit', 'loss', 'margin', 'eps', \n",
    "    'guidance', 'forecast', 'outlook', 'quarter', 'quarterly',\n",
    "    'annual', 'fiscal', 'billion', 'million', 'trillion',\n",
    "    \n",
    "    # Market Movement\n",
    "    'bull', 'bear', 'rally', 'surge', 'soar', 'jump', 'climb',\n",
    "    'drop', 'fall', 'crash', 'plunge', 'sink', 'tumble', 'volatile',\n",
    "    'gain', 'rise', 'decline', 'dip',\n",
    "    \n",
    "    # Valuation\n",
    "    'valuation', 'market cap', 'price target', 'rating', 'upgrade',\n",
    "    'downgrade', 'buy', 'sell', 'hold', 'overweight', 'underweight',\n",
    "    \n",
    "    # Business Operations  \n",
    "    'ceo', 'cfo', 'executive', 'board', 'investor', 'shareholder',\n",
    "    'dividend', 'buyback', 'acquisition', 'merger', 'deal', 'partnership',\n",
    "    'investment', 'ipo', 'stake',\n",
    "    \n",
    "    # Supply Chain & Operations\n",
    "    'supplier', 'supply chain', 'manufacture', 'production', 'factory',\n",
    "    'chip', 'semiconductor', 'shortage',\n",
    "    \n",
    "    # Tech-Specific\n",
    "    'ai', 'artificial intelligence', 'cloud', 'software', 'hardware',\n",
    "    'iphone', 'android', 'windows', 'azure', 'aws', 'gpu', 'data center',\n",
    "    \n",
    "    # MAG7 Company Names (catches articles about them)\n",
    "    'apple', 'microsoft', 'google', 'alphabet', 'amazon', 'meta', \n",
    "    'facebook', 'tesla', 'nvidia', 'aapl', 'msft', 'googl', 'amzn', \n",
    "    'tsla', 'nvda',\n",
    "    \n",
    "    # Competition & Industry\n",
    "    'competitor', 'rival', 'industry', 'sector', 'antitrust', 'regulation',\n",
    "    'ces', 'tech trends', 'conference', 'keynote', 'announcement', 'launch', 'unveil'\n",
    "]\n",
    "def has_financial_keyword(title):\n",
    "    title_lower = title.lower()\n",
    "    for kw in financial_keywords:\n",
    "        # Use word boundary \\b to match whole words only\n",
    "        if re.search(r'\\b' + re.escape(kw) + r'\\b', title_lower):\n",
    "            return True\n",
    "    return False\n",
    "df_clean['is_relevant'] = df_clean['title'].apply(has_financial_keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles with financial keywords: 225\n",
      "Potential irrelevant: 73\n"
     ]
    }
   ],
   "source": [
    "print(f\"Articles with financial keywords: {df_clean['is_relevant'].sum()}\")\n",
    "print(f\"Potential irrelevant: {(~df_clean['is_relevant']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potentially irrelevant titles:\n",
      "['Trump Biggest Inaugural Donor Benefits from Worker Safety Weakening'\n",
      " 'Jim Cramer Says  There a Lot of Value in Nike  '\n",
      " 'Spotify Halts ICE Recruitment Ads Amid 2025 Backlash and Ethics Debate'\n",
      " 'T - Mobile Launches Better Value Plan : Unlimited 5G , Streaming Perks for $140'\n",
      " 'Unicode Unveils Emoji 18 . 0 Draft : Squinting Face , Pickle , and More for 2027'\n",
      " 'US Market Open : US equity futures are modestly lower , whilst DXY is flat as market awaits US CPI - Newsquawk US Opening News'\n",
      " 'Here a look at some of the key topics coming up this legislative session'\n",
      " 'Best website research tools for competitive intelligence and market analysis'\n",
      " 'US Market Open : US equity futures are modestly lower , whilst DXY is flat as market awaits US CPI - Newsquawk US Opening News'\n",
      " '5 Highly Anticipated Games That Could Miss 2026']\n"
     ]
    }
   ],
   "source": [
    "# Preview potentially irrelevant articles\n",
    "print(\"\\nPotentially irrelevant titles:\")\n",
    "print(df_clean[~df_clean['is_relevant']]['title'].head(10).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows after relevance filter: 225\n"
     ]
    }
   ],
   "source": [
    "#keep only relevant data \n",
    "df_clean = df_clean[df_clean['is_relevant'] ==  True]\n",
    "print(f\"Clean rows after relevance filter: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False <- '20 Canadian albums we cant wait to hear in 2026'\n",
      "True <- 'Apple stock rises 5%'\n",
      "False <- 'How Hermès keeps its clutches on its own handbags'\n"
     ]
    }
   ],
   "source": [
    "# Debug: Test the function directly\n",
    "test_titles = [\n",
    "    \"20 Canadian albums we cant wait to hear in 2026\",\n",
    "    \"Apple stock rises 5%\",\n",
    "    \"How Hermès keeps its clutches on its own handbags\"\n",
    "]\n",
    "\n",
    "for title in test_titles:\n",
    "    result = has_financial_keyword(title)\n",
    "    print(f\"{result} <- '{title[:50]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['is_relevant']==True]\n",
    "df_clean = df_clean.drop(columns=['is_relevant', 'query' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seendate</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>domain</th>\n",
       "      <th>socialimage</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-13 15:00:00+00:00</td>\n",
       "      <td>https://finance.yahoo.com/news/prediction-spec...</td>\n",
       "      <td>Prediction : This Spectacular Vanguard ETF Wil...</td>\n",
       "      <td>English</td>\n",
       "      <td>finance.yahoo.com</td>\n",
       "      <td>https://s.yimg.com/ny/api/res/1.2/vPftkj6hH9si...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-13 15:00:00+00:00</td>\n",
       "      <td>https://www.proactiveinvestors.com/companies/n...</td>\n",
       "      <td>S &amp; P and Nasdaq hold as Dow starts lower desp...</td>\n",
       "      <td>English</td>\n",
       "      <td>proactiveinvestors.com</td>\n",
       "      <td>https://cdn.proactiveinvestors.com/eyJidWNrZXQ...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-13 14:45:00+00:00</td>\n",
       "      <td>http://www.thailandnews.net/news/278802381/aut...</td>\n",
       "      <td>Auto industry bets on AI partnerships after co...</td>\n",
       "      <td>English</td>\n",
       "      <td>thailandnews.net</td>\n",
       "      <td>https://image.chitra.live/api/v1/wps/ed80633/b...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2026-01-13 14:30:00+00:00</td>\n",
       "      <td>https://edition.cnn.com/2026/01/13/tech/plan-a...</td>\n",
       "      <td>How Amazon plans to catch up to ChatGPT</td>\n",
       "      <td>English</td>\n",
       "      <td>edition.cnn.com</td>\n",
       "      <td>https://media.cnn.com/api/v1/images/stellar/pr...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2026-01-13 14:30:00+00:00</td>\n",
       "      <td>https://nypost.com/2026/01/13/business/jpmorga...</td>\n",
       "      <td>JPMorgan profit takes a hit as it builds reser...</td>\n",
       "      <td>English</td>\n",
       "      <td>nypost.com</td>\n",
       "      <td>https://nypost.com/wp-content/uploads/sites/2/...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2026-01-13 14:30:00+00:00</td>\n",
       "      <td>https://abcnews.go.com/Technology/wireStory/go...</td>\n",
       "      <td>Google corporate parent joins $4 trillion club...</td>\n",
       "      <td>English</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>https://i.abcnewsfe.com/a/bb8e059a-24ff-4961-9...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2026-01-13 14:30:00+00:00</td>\n",
       "      <td>https://economictimes.indiatimes.com/news/inte...</td>\n",
       "      <td>why JPM stock is rising despite earnings miss ...</td>\n",
       "      <td>English</td>\n",
       "      <td>economictimes.indiatimes.com</td>\n",
       "      <td>https://img.etimg.com/thumb/msid-126506651,wid...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2026-01-13 14:30:00+00:00</td>\n",
       "      <td>https://www.insidermonkey.com/blog/jim-cramer-...</td>\n",
       "      <td>Jim Cramer Calls Alphabet Gemini 3 a  Home Run</td>\n",
       "      <td>English</td>\n",
       "      <td>insidermonkey.com</td>\n",
       "      <td>https://d2gr5kl7dt2z3t.cloudfront.net/blog/wp-...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2026-01-13 14:15:00+00:00</td>\n",
       "      <td>https://www.webpronews.com/evercore-isi-lifts-...</td>\n",
       "      <td>Evercore ISI Lifts Apple Price Target to $330 ...</td>\n",
       "      <td>English</td>\n",
       "      <td>webpronews.com</td>\n",
       "      <td>https://www.webpronews.com/wp-content/uploads/...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2026-01-13 14:15:00+00:00</td>\n",
       "      <td>https://timesofindia.indiatimes.com/education/...</td>\n",
       "      <td>Google has hired tons of people without coll...</td>\n",
       "      <td>English</td>\n",
       "      <td>timesofindia.indiatimes.com</td>\n",
       "      <td>https://static.toiimg.com/thumb/msid-126506318...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    seendate  \\\n",
       "2  2026-01-13 15:00:00+00:00   \n",
       "3  2026-01-13 15:00:00+00:00   \n",
       "4  2026-01-13 14:45:00+00:00   \n",
       "9  2026-01-13 14:30:00+00:00   \n",
       "10 2026-01-13 14:30:00+00:00   \n",
       "11 2026-01-13 14:30:00+00:00   \n",
       "12 2026-01-13 14:30:00+00:00   \n",
       "16 2026-01-13 14:30:00+00:00   \n",
       "17 2026-01-13 14:15:00+00:00   \n",
       "18 2026-01-13 14:15:00+00:00   \n",
       "\n",
       "                                                  url  \\\n",
       "2   https://finance.yahoo.com/news/prediction-spec...   \n",
       "3   https://www.proactiveinvestors.com/companies/n...   \n",
       "4   http://www.thailandnews.net/news/278802381/aut...   \n",
       "9   https://edition.cnn.com/2026/01/13/tech/plan-a...   \n",
       "10  https://nypost.com/2026/01/13/business/jpmorga...   \n",
       "11  https://abcnews.go.com/Technology/wireStory/go...   \n",
       "12  https://economictimes.indiatimes.com/news/inte...   \n",
       "16  https://www.insidermonkey.com/blog/jim-cramer-...   \n",
       "17  https://www.webpronews.com/evercore-isi-lifts-...   \n",
       "18  https://timesofindia.indiatimes.com/education/...   \n",
       "\n",
       "                                                title language  \\\n",
       "2   Prediction : This Spectacular Vanguard ETF Wil...  English   \n",
       "3   S & P and Nasdaq hold as Dow starts lower desp...  English   \n",
       "4   Auto industry bets on AI partnerships after co...  English   \n",
       "9             How Amazon plans to catch up to ChatGPT  English   \n",
       "10  JPMorgan profit takes a hit as it builds reser...  English   \n",
       "11  Google corporate parent joins $4 trillion club...  English   \n",
       "12  why JPM stock is rising despite earnings miss ...  English   \n",
       "16   Jim Cramer Calls Alphabet Gemini 3 a  Home Run    English   \n",
       "17  Evercore ISI Lifts Apple Price Target to $330 ...  English   \n",
       "18    Google has hired tons of people without coll...  English   \n",
       "\n",
       "                          domain  \\\n",
       "2              finance.yahoo.com   \n",
       "3         proactiveinvestors.com   \n",
       "4               thailandnews.net   \n",
       "9                edition.cnn.com   \n",
       "10                    nypost.com   \n",
       "11                abcnews.go.com   \n",
       "12  economictimes.indiatimes.com   \n",
       "16             insidermonkey.com   \n",
       "17                webpronews.com   \n",
       "18   timesofindia.indiatimes.com   \n",
       "\n",
       "                                          socialimage company ticker  \n",
       "2   https://s.yimg.com/ny/api/res/1.2/vPftkj6hH9si...   Apple   AAPL  \n",
       "3   https://cdn.proactiveinvestors.com/eyJidWNrZXQ...   Apple   AAPL  \n",
       "4   https://image.chitra.live/api/v1/wps/ed80633/b...   Apple   AAPL  \n",
       "9   https://media.cnn.com/api/v1/images/stellar/pr...   Apple   AAPL  \n",
       "10  https://nypost.com/wp-content/uploads/sites/2/...   Apple   AAPL  \n",
       "11  https://i.abcnewsfe.com/a/bb8e059a-24ff-4961-9...   Apple   AAPL  \n",
       "12  https://img.etimg.com/thumb/msid-126506651,wid...   Apple   AAPL  \n",
       "16  https://d2gr5kl7dt2z3t.cloudfront.net/blog/wp-...   Apple   AAPL  \n",
       "17  https://www.webpronews.com/wp-content/uploads/...   Apple   AAPL  \n",
       "18  https://static.toiimg.com/thumb/msid-126506318...   Apple   AAPL  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the same story gets reported by multiple outlets with slightly different titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher #comparing sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1412 near duplicate pairs\n",
      "\n",
      "100% similar:\n",
      "  1: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n",
      "  2: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n",
      "\n",
      "100% similar:\n",
      "  1: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n",
      "  2: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n",
      "\n",
      "100% similar:\n",
      "  1: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n",
      "  2: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n",
      "\n",
      "100% similar:\n",
      "  1: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n",
      "  2: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n",
      "\n",
      "100% similar:\n",
      "  1: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n",
      "  2: Prediction : This Spectacular Vanguard ETF Will Beat the S &...\n"
     ]
    }
   ],
   "source": [
    "def similar(a,b):\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
    "\n",
    "#Find titles that >80% similar\n",
    "titles = df_clean['title'].tolist()\n",
    "near_dupes=[]\n",
    "for i, t1 in enumerate(titles):\n",
    "    for j, t2 in enumerate(titles[i+1:], i+1):\n",
    "        if similar(t1, t2) > 0.8:\n",
    "            near_dupes.append((t1,t2,similar(t1,t2)))\n",
    "\n",
    "print(f\"Found {len(near_dupes)} near duplicate pairs\")\n",
    "for t1, t2, score in near_dupes[:5]:\n",
    "    print(f\"\\n{score:.0%} similar:\")\n",
    "    print(f\"  1: {t1[:60]}...\")\n",
    "    print(f\"  2: {t2[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [title, company, ticker]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check one of the duplicate titles\n",
    "dupe_title = \"Apple Is Losing Its Grip on the World Tech Supply Chain\"\n",
    "print(df_clean[df_clean['title'] == dupe_title][['title', 'company', 'ticker']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 225 rows to ../data/processed/gdelt_articles_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "print(f\"Saved {len(df_clean)} rows to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final clean data: 225 rows\n",
      "Saved to ../data/processed/gdelt_articles_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# All cleaning in one cell (near the end of notebook)\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.drop(columns=['description', 'sourceCountry'])\n",
    "df_clean = df_clean.drop_duplicates(subset=['url', 'company'], keep='first')\n",
    "df_clean = df_clean[df_clean['language'] == 'English']\n",
    "df_clean = df_clean[df_clean['title'].apply(has_financial_keyword)]\n",
    "df_clean = df_clean.drop(columns=['query'])\n",
    "\n",
    "print(f\"Final clean data: {len(df_clean)} rows\")\n",
    "\n",
    "# Save immediately after\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (market-sentiment)",
   "language": "python",
   "name": "market-sentiment-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
